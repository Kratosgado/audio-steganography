{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "17qEJhBbwEHArKs-tAGZ6fZUcf60pMwo4",
      "authorship_tag": "ABX9TyM50Fx71+mV94GsYWzPoIbw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kratosgado/audio-steganography/blob/main/steg-ai/core_modules/Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXp8Vn1BAu2P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3 shimmy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.distributions import Normal\n",
        "from scipy.signal import get_window\n",
        "from scipy.fft import dct, idct\n",
        "import scipy.io.wavfile as wf\n",
        "import scipy\n",
        "import requests\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import gym\n",
        "from gym import spaces\n",
        "import random\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor"
      ],
      "metadata": {
        "id": "iZE9vuGCIj4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "FRAME_SIZE = 1024 #2048\n",
        "HOP_LENGTH = 256 #512\n",
        "NON_CRITICAL_PERCENT = 0.1 # Modify bottom 10% of coeffs by magnitude\n",
        "STATE_DIM = 1024\n",
        "SAMPLE_RATE = 22050\n",
        "N_MELS = 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5uq1C49Mc3w",
        "outputId": "c0fe3d2d-0379-4bb4-c195-24b8cee1486e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- UTILITY FUNCTIONS ---"
      ],
      "metadata": {
        "id": "iNC_gfrXNLFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, local_filename): # gemini\n",
        "  \"\"\"Downloads a file if it doesn't already exist.\"\"\"\n",
        "  if not os.path.exists(local_filename):\n",
        "    print(f\"Downloading {local_filename}...\")\n",
        "    with requests.get(url, stream=True) as r:\n",
        "      r.raise_for_status()\n",
        "      with open(local_filename, 'wb') as f:\n",
        "        for chunk in r.iter_content(chunk_size=8192):\n",
        "          f.write(chunk)\n",
        "    print(f\"{local_filename} downloaded successfully.\")\n",
        "  else:\n",
        "    print(f\"{local_filename} already exists.\")\n",
        "\n",
        "NORM_NUM = 32768"
      ],
      "metadata": {
        "id": "_55FxjzNNKHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- HYPERPARAMETERS ---"
      ],
      "metadata": {
        "id": "HV_OdAlXNoLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config: # gemini\n",
        "  \"\"\"Class to hold all hyperparameters.\"\"\"\n",
        "  #Audio processing\n",
        "  FRAME_SIZE = 1024 #2048\n",
        "  HOP_LENGTH = 256 #512\n",
        "  NON_CRITICAL_PERCENT = 0.1 # Modify bottom 10% of coeffs by magnitude\n",
        "  STATE_DIM = 1024\n",
        "  SAMPLE_RATE = 22050\n",
        "  N_MELS = 128\n",
        "\n",
        "  # RL Training\n",
        "  EPISODES = 1000\n",
        "  LEARNING_RATE_ACTOR = 3e-4\n",
        "  LEARNING_RATE_CRITIC = 3e-4\n",
        "  GAMMA = 0.99 # Discount factor\n",
        "  GAE_LAMBDA = 0.95 # Lambda for Generalized Advantage Estimation\n",
        "  PPO_EPSILON = 0.2 # Epsilon for clipping in PPO\n",
        "  PPO_EPOCHS = 10 # Number of epochs for PPO update\n",
        "  BATCH_SIZE = 64\n",
        "\n",
        "  # Environment Network Pre-training\n",
        "  PRETRAIN_EPOCHS = 10\n",
        "  PRE_TRAIN_LR = 1e-3\n",
        "  PRE_TRAIN_BATCH_SIZE = 32\n",
        "\n",
        "  # Reward weights\n",
        "  SNR_WEIGHTS = 0.02 # Weight for SNR in reward. Tuned to be on a similar scale to detection prob.\n",
        "  DETECTION_WEIGHT = 1.0 # Weight for detection probability in reward.\n",
        "  IMPERCEPTIBILITY_WEIGHT = 0.3\n",
        "  UNDETECTABILITY_WEIGHT = 0.4\n",
        "  EXTRACTION_ACCURACY_WEIGHT = 0.3"
      ],
      "metadata": {
        "id": "SLavUsivNtBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 1: AUDIO PREPROCESSOR ---"
      ],
      "metadata": {
        "id": "W-feRKGXJB5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioPreprocessor:\n",
        "  \"\"\"Handles audio loading, MDCT, and inverse MDCT.\"\"\"\n",
        "  def __init__(self, audio_path= None, audio_data=None, frame_size=1024, hop_length=256, sr=22050):\n",
        "    if audio_path:\n",
        "      self.audio, self.sr = librosa.load(audio_path, sr=sr, mono=True)\n",
        "    elif audio_data is not None:\n",
        "      self.audio = audio_data\n",
        "      self.sr = sr\n",
        "    else:\n",
        "      raise ValueError(\"Either audio_path or audio_data must be provided\")\n",
        "\n",
        "    # Normalize audio\n",
        "    self.audio = self.audio / np.max(np.abs(self.audio))\n",
        "    self.frame_size = frame_size\n",
        "    self.hop_length = hop_length\n",
        "    self.window = get_window('hann', self.frame_size)\n",
        "    # return self.audio, self.sr\n",
        "\n",
        "  def load_audio(self, path):\n",
        "    \"\"\"Load WAV audio file\"\"\"\n",
        "    audio, _ = librosa.load(path, sr=self.sr)\n",
        "    return audio\n",
        "\n",
        "  def stft(self, audio):\n",
        "    \"\"\"Compute Short-Time Fourier Transform (STFT)\"\"\"\n",
        "    return librosa.stft(audio, n_fft=self.frame_size, hop_length=self.hop_length)\n",
        "\n",
        "  def istft(self, stft_matrix):\n",
        "    \"\"\"Compute Inverse Short-Time Fourier Transform (ISTFT)\"\"\"\n",
        "    return librosa.istft(stft_matrix, hop_length=self.hop_length)\n",
        "\n",
        "  def compute_mdct(self):\n",
        "    \"\"\"Compute Modified Discrete Cosine Transform (MDCT) using STFT and DCT from librosa\"\"\"\n",
        "    stft = self.stft(self.audio)\n",
        "    magnitudes = np.abs(stft)\n",
        "    phases = np.angle(stft)\n",
        "    return magnitudes, phases\n",
        "\n",
        "  def inverse_qmdct(self, qmdct_coeffs: np.ndarray) -> np.ndarray:\n",
        "    pass\n",
        "\n",
        "  def get_non_critical_coeffs(self, magnitudes, percentile=10):\n",
        "    \"\"\"Identify non-critical coefficients (lowest magnitude)\"\"\"\n",
        "    threshold = np.percentile(np.abs(magnitudes.flatten()), percentile)\n",
        "    mask = np.abs(magnitudes) < threshold\n",
        "    return mask\n",
        "\n",
        "  def reconstruct_audio(self, magnitudes, phases):\n",
        "    \"\"\"Reconstruct audio from magnitude/stft matrix and phase/non_critical_coeffs\"\"\"\n",
        "    stft = magnitudes * np.exp(1j * phases)\n",
        "    reconstructed_audio = self.istft(stft)\n",
        "    return reconstructed_audio\n",
        "\n",
        "  def plot_spectrogram(self, title):\n",
        "    \"\"\"Visualize audio spectrogram\"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    S = librosa.amplitude_to_db(np.abs(librosa.stft(self.audio)), ref=np.max)\n",
        "    librosa.display.specshow(S, sr=self.sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "  def save_audio(self, audio: np.ndarray, sr: int, path: str):\n",
        "    wf.write(path,sr, (audio * NORM_NUM).astype(np.int16))"
      ],
      "metadata": {
        "id": "z-rBWB4UJAyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 2: RL ACTOR-CRITIC NETWORKS ---"
      ],
      "metadata": {
        "id": "wfre1MB1Julg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "  \"\"\"Actor Network: Decides on the modification scale.\"\"\"\n",
        "  def __init__(self, input_dim, hidden_dim=256):\n",
        "    super(PolicyNetwork, self).__init__()\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.mean_layer = nn.Linear(hidden_dim, 1)\n",
        "    self.log_std_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    features = self.fc(x)\n",
        "    mean = self.mean_layer(features)\n",
        "    log_std = self.log_std_layer(features)\n",
        "    log_std = torch.clamp(log_std, min=-20, max=2)  # Constrain for stability\n",
        "    return mean, log_std\n",
        "\n",
        "  def sample_action(self, state):\n",
        "    \"\"\"Sample action from policy distribution\"\"\"\n",
        "    state_tensor = torch.as_tensor(state, dtype=torch.float32).to(device)\n",
        "    mean, log_std = self.forward(state_tensor)\n",
        "    std = torch.exp(log_std)\n",
        "    normal_dist = torch.distributions.Normal(mean, std)\n",
        "    action = normal_dist.sample()\n",
        "    return action.cpu().detach().numpy().flatten()\n",
        "\n",
        "# 7. Feature Extractor for PPO\n",
        "class CustomFeatureExtractor(BaseFeaturesExtractor):\n",
        "  def __init__(self, observation_space: spaces.Box, features_dim = 128):\n",
        "    super().__init__(observation_space, features_dim)\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(observation_space.shape[0], 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, features_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
        "    return self.net(observations)\n",
        "\n",
        "class ValueNetwork(nn.Module):\n",
        "  \"\"\"Critic Network: Estimates the value of state.\"\"\"\n",
        "  def __init__(self, input_dim) -> None:\n",
        "    super(ValueNetwork, self).__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, state):\n",
        "    return self.network(state)"
      ],
      "metadata": {
        "id": "UmJ4bvTvJeK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 3: ENVIRONMENT NETWORK (STEGANALYZER) ---"
      ],
      "metadata": {
        "id": "EH5KOS4wJw0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SteganalysisCNN(nn.Module):\n",
        "  \"\"\"A 1D CNN that acts as a steganalysis tool.\"\"\"\n",
        "  def __init__(self, input_channels=1):\n",
        "    super(SteganalysisCNN, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv1d(input_channels, 32, kernel_size=5, stride=2, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=2),\n",
        "        nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=2),\n",
        "        nn.Flatten()\n",
        "    )\n",
        "\n",
        "    # Calculate output dimension after convolutions\n",
        "    test_input = torch.randn(1, input_channels, 500)\n",
        "    conv_output_dim = self.conv(test_input).shape[-1]\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(conv_output_dim, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return self.fc(x)\n",
        "\n",
        " #5. Custom Gym Environment for RL Training\n",
        "class AudioStegoEnv(gym.Env):\n",
        "  def __init__(self, audio_path, message):\n",
        "    super(AudioStegoEnv, self).__init__()\n",
        "\n",
        "    # Initialize audio and message\n",
        "    self.preprocessor = AudioPreprocessor(audio_path=audio_path)\n",
        "    self.original_audio = self.preprocessor.audio.copy()\n",
        "    self.message = message\n",
        "\n",
        "    # Compute initial features\n",
        "    magnitudes, _ = self.preprocessor.compute_mdct()\n",
        "    self.mask = self.preprocessor.get_non_critical_coeffs(magnitudes)\n",
        "\n",
        "    # Define action and observation spaces\n",
        "    self.action_space = spaces.Box(low=0.0, high=0.1, shape=(1,), dtype=np.float32)\n",
        "    self.observation_space = spaces.Box(low=-1.0, high=1.0,\n",
        "                                        shape=(N_MELS,), dtype=np.float32)\n",
        "\n",
        "    # Initialize state\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Reset environment to initial state\"\"\"\n",
        "    self.current_audio = self.original_audio.copy()\n",
        "    self.current_step = 0\n",
        "    return self._get_obs()\n",
        "\n",
        "  def _get_obs(self):\n",
        "    \"\"\"Extract MFCC features as observation\"\"\"\n",
        "    mfcc = librosa.feature.mfcc(y=self.current_audio, sr=SAMPLE_RATE,\n",
        "                                n_mfcc=N_MELS, n_fft=FRAME_SIZE,\n",
        "                                hop_length=HOP_LENGTH)\n",
        "    return np.mean(mfcc, axis=1)\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Execute one embedding step\"\"\"\n",
        "    alpha = action[0]\n",
        "\n",
        "    # Compute MDCT\n",
        "    magnitudes, phases = self.preprocessor.compute_mdct()\n",
        "\n",
        "    # Embed message\n",
        "    stego_system = EmbeddingModule()\n",
        "    modified_magnitudes = stego_system.embed(magnitudes, self.mask, self.message, alpha)\n",
        "\n",
        "    # Reconstruct audio\n",
        "    self.current_audio = self.preprocessor.reconstruct_audio(modified_magnitudes, phases)\n",
        "\n",
        "    # Compute rewards\n",
        "    snr = self._calculate_snr()\n",
        "    detection_prob = self._simulate_detection()\n",
        "    reward = self._calculate_reward(snr, detection_prob)\n",
        "\n",
        "    # Update state\n",
        "    self.current_step += 1\n",
        "    done = self.current_step >= 10  # Train for 10 steps\n",
        "\n",
        "    return self._get_obs(), reward, done, {\n",
        "        \"snr\": snr,\n",
        "        \"detection_prob\": detection_prob\n",
        "    }\n",
        "\n",
        "  def _calculate_snr(self):\n",
        "    \"\"\"Calculate Signal-to-Noise Ratio\"\"\"\n",
        "    # Ensure both audio arrays have the same length before calculating noise\n",
        "    min_len = min(len(self.current_audio), len(self.original_audio))\n",
        "    current_audio_trimmed = self.current_audio[:min_len]\n",
        "    original_audio_trimmed = self.original_audio[:min_len]\n",
        "\n",
        "    noise = current_audio_trimmed - original_audio_trimmed\n",
        "    signal_power = np.mean(original_audio_trimmed ** 2)\n",
        "    noise_power = np.mean(noise ** 2)\n",
        "\n",
        "    if noise_power == 0:\n",
        "        return 100  # High SNR if no noise\n",
        "\n",
        "    return 10 * np.log10(signal_power / noise_power)\n",
        "\n",
        "  def _simulate_detection(self):\n",
        "    \"\"\"Simulate steganalysis detection\"\"\"\n",
        "    # In a real implementation, we would use the steganalysis network\n",
        "    # For simulation, we use a probability based on SNR\n",
        "    snr = self._calculate_snr()\n",
        "    return 1 / (1 + np.exp(0.5 * (snr - 50)))  # Logistic function\n",
        "\n",
        "  def _calculate_reward(self, snr, detection_prob):\n",
        "    \"\"\"Calculate reward balancing SNR and detectability\"\"\"\n",
        "    # Target: SNR > 50 dB, detection_prob < 0.1\n",
        "    snr_reward = min(snr / 50, 1.0)\n",
        "    detect_reward = 1.0 - min(detection_prob, 1.0)\n",
        "\n",
        "    # Weighted combination\n",
        "    return 0.7 * snr_reward + 0.3 * detect_reward"
      ],
      "metadata": {
        "id": "Vk-lzxwRJt0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 4: Proximal Policy Optimization(PPO) AGENT ---"
      ],
      "metadata": {
        "id": "XipcHhGAJ6OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PPOAgent:\n",
        "  \"\"\"The PPO agent that handles policy updates.\"\"\"\n",
        "  def __init__(self, policy_net, value_net, actor_lr, critic_lr,gamma, ppo_epsilon, ppo_epochs) -> None:\n",
        "    self.actor = policy_net\n",
        "    self.critic = value_net\n",
        "    self.optimizer_actor = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
        "    self.optimizer_critic = optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
        "    self.ppo_epsilon = ppo_epsilon\n",
        "    self.ppo_epochs = ppo_epochs\n",
        "    self.gamma = gamma\n",
        "    self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    # Experience buffer\n",
        "    self.states = []\n",
        "    self.actions = []\n",
        "    self.log_probs = []\n",
        "    self.rewards = []\n",
        "    self.is_terminals = []\n",
        "\n",
        "  def train(self, states, actions, old_log_probs, rewards, values):\n",
        "    pass\n",
        "\n",
        "  def update(self):\n",
        "    \"\"\"Update policy using PPO\"\"\"\n",
        "    if len(self.states) == 0:\n",
        "      return\n",
        "\n",
        "    # get data from memory\n",
        "    old_states = torch.stack(self.states).to(device)\n",
        "    old_actions = torch.stack(self.actions).to(device)\n",
        "    old_log_probs = torch.stack(self.log_probs).detach().to(device)\n",
        "    returns = self.compute_returns().to(device)\n",
        "    # advantages = torch.tensor(np.array(memory['advantages']), dtype=torch.float32).to(device)\n",
        "\n",
        "    # normalize advantages\n",
        "    # advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
        "    returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n",
        "\n",
        "    # PPO update\n",
        "    for _ in range(self.ppo_epochs):\n",
        "      # get new log probs, and entropy from the current policy\n",
        "      mean, std = self.actor(old_states)\n",
        "      dist = Normal(mean, std)\n",
        "      new_log_probs = dist.log_prob(old_actions)\n",
        "\n",
        "      # values = self.critic(old_states).squeeze()\n",
        "      # entropy = dist.entropy().mean() # for potential entropy bonus (not used here)\n",
        "\n",
        "      # Actor (Policy) Loss\n",
        "      # Calculate the ratio of new to old probs\n",
        "      ratio = torch.exp(new_log_probs - old_log_probs)\n",
        "\n",
        "      # PPO's clipped objective\n",
        "      # advantages = returns - values\n",
        "      advantages = returns\n",
        "      surr1 = ratio * advantages\n",
        "      surr2 = torch.clamp(ratio, 1 - self.ppo_epsilon, 1 + self.ppo_epsilon) * advantages\n",
        "      actor_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "      # Critic (Value) Loss\n",
        "      # critic_loss = self.mse_loss(values, returns)\n",
        "\n",
        "      # update actor\n",
        "      self.optimizer_actor.zero_grad()\n",
        "      actor_loss.backward()\n",
        "      self.optimizer_actor.step()\n",
        "\n",
        "      # Update critic\n",
        "      # self.optimizer_critic.zero_grad()\n",
        "      # critic_loss.backward()\n",
        "      # self.optimizer_critic.step()\n",
        "\n",
        "    self.clear_buffer()\n",
        "\n",
        "  def compute_gae(self, rewards, values, masks): # qwen\n",
        "    \"\"\"Compute Generalized Advantage Estimation (GAE)\"\"\"\n",
        "    # advantages = []\n",
        "    # gae = 0\n",
        "    # for i in reversed(range(len(rewards))):\n",
        "    #   delta = rewards[i] + self.gamma * values[i+1] * (1 - dones[i]) - values[i]\n",
        "    #   gae = delta + self.gamma * 0.95 * (1 - dones[i]) * gae\n",
        "    #   advantages.insert(0, gae)\n",
        "    # return torch.tensor(advantages, dtype=torch.float32)\n",
        "    pass\n",
        "\n",
        "  def store_experience(self, state, action, log_prob, reward, is_terminal): # claude\n",
        "    self.states.append(state)\n",
        "    self.actions.append(action)\n",
        "    self.log_probs.append(log_prob)\n",
        "    self.rewards.append(reward)\n",
        "    self.is_terminals.append(is_terminal)\n",
        "\n",
        "  def compute_returns(self): # claude\n",
        "    \"\"\"Compute discounted returns for each state.\"\"\"\n",
        "    returns = []\n",
        "    discounted_sum = 0\n",
        "\n",
        "    for reward, is_terminal in zip(reversed(self.rewards), reversed(self.is_terminals)):\n",
        "      if is_terminal:\n",
        "        discounted_sum = 0\n",
        "      discounted_sum = reward + self.gamma * discounted_sum\n",
        "      returns.insert(0, discounted_sum)\n",
        "\n",
        "    return torch.tensor(returns, dtype=torch.float32)\n",
        "\n",
        "  def clear_buffer(self): # claude\n",
        "    \"\"\"Clear the experience buffer.\"\"\"\n",
        "    self.states.clear()\n",
        "    self.actions.clear()\n",
        "    self.log_probs.clear()\n",
        "    self.rewards.clear()\n",
        "    self.is_terminals.clear()"
      ],
      "metadata": {
        "id": "bjvXp-wiJ46b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 5: EMBEDDING/EXTRACTION MODULE ---\n",
        "Main framework class"
      ],
      "metadata": {
        "id": "hyIIZSInKMwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingModule:\n",
        "  \"\"\"Embeds and extracts messages from MDCT coefficients.\"\"\"\n",
        "  def __init__(self, steganalysis_net=None):\n",
        "        self.steganalysis_net = steganalysis_net\n",
        "        if self.steganalysis_net:\n",
        "            self.steganalysis_net.to(device)\n",
        "            self.steganalysis_net.eval()\n",
        "\n",
        "  def embed(self, magnitudes, mask, message, alpha=0.01):\n",
        "    \"\"\"Embed message using sign encoding in non-critical coefficients\"\"\"\n",
        "    # Convert message to binary\n",
        "    bin_message = ''.join(format(ord(char), '08b') for char in message)\n",
        "    bin_message = np.array([int(bit) for bit in bin_message])\n",
        "\n",
        "    # Apply mask to get non-critical coefficients\n",
        "    coeffs = magnitudes.copy()\n",
        "    non_critical = coeffs[mask]\n",
        "\n",
        "    # Ensure we have enough coefficients for the message\n",
        "    if len(non_critical) < len(bin_message):\n",
        "        raise ValueError(\"Message too long for available non-critical coefficients\")\n",
        "\n",
        "    # Embed message using sign encoding\n",
        "    for i, bit in enumerate(bin_message):\n",
        "        sign = 1 if bit == 1 else -1\n",
        "        non_critical[i] = sign * np.abs(non_critical[i]) * (1 + alpha)\n",
        "\n",
        "    # Update coefficients\n",
        "    coeffs[mask] = non_critical\n",
        "    return coeffs\n",
        "\n",
        "  def extract(self, magnitudes, mask, message_length):\n",
        "    \"\"\"Extract message from non-critical coefficients\"\"\"\n",
        "    # Apply mask to get non-critical coefficients\n",
        "    non_critical = magnitudes[mask]\n",
        "\n",
        "    # Extract message from sign\n",
        "    bin_message = []\n",
        "    for i in range(message_length * 8):\n",
        "        sign = 1 if non_critical[i] >= 0 else -1\n",
        "        bit = 1 if sign > 0 else 0\n",
        "        bin_message.append(str(bit))\n",
        "\n",
        "    # Convert binary to string\n",
        "    bin_str = ''.join(bin_message)\n",
        "    chars = [chr(int(bin_str[i:i+8], 2)) for i in range(0, len(bin_str), 8)]\n",
        "    return ''.join(chars)\n",
        "\n",
        "  def find_embeddable_indices(self,  mdct_coeffs: np.ndarray):\n",
        "    \"\"\"Finds non-critical coefficients suitable for embedding.\"\"\"\n",
        "    magnitudes = np.abs(mdct_coeffs.flatten())\n",
        "    num_to_select = int(len(magnitudes) * self.non_critical_percent)\n",
        "\n",
        "    # Get indices of the smallest coefficients\n",
        "    sorted_indices = np.argsort(magnitudes)\n",
        "    embeddable_indices_flat = sorted_indices[:num_to_select]\n",
        "\n",
        "    # Convert flat indices back to 2D\n",
        "    embeddable_indices = np.unravel_index(embeddable_indices_flat, mdct_coeffs.shape)\n",
        "    return embeddable_indices\n",
        "\n",
        "  def detect(self, audio):\n",
        "    \"\"\"Compute detection probability using steganalysis network\"\"\"\n",
        "    if not self.steganalysis_net:\n",
        "      raise ValueError(\"Steganalysis network not initialized\")\n",
        "\n",
        "    # Convert to tensor\n",
        "    audio_tensor = torch.as_tensor(audio, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prob = self.steganalysis_net(audio_tensor).item()\n",
        "    return prob"
      ],
      "metadata": {
        "id": "bc5xRFmqKK_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -- MAIN FRAMEWORK --"
      ],
      "metadata": {
        "id": "A69oR2apRBwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RLAudioSteganography:\n",
        "  \"\"\"Main framework class\"\"\"\n",
        "  def __init__(self, cfg: Config) -> None:\n",
        "    self.cfg = cfg\n",
        "\n",
        "  def Initialize_components(self, audio_path):\n",
        "    \"\"\"Initialize components\"\"\"\n",
        "    self.preprocessor = AudioPreprocessor(audio_path=audio_path)\n",
        "    self.magnitudes, self.phases = self.preprocessor.compute_mdct()\n",
        "    self.mask = self.preprocessor.get_non_critical_coeffs(self.magnitudes)\n",
        "    self.steganalysis_net = SteganalysisCNN(input_channels=len(self.preprocessor.audio))\n",
        "    self.steganalysis_net.to(device)\n",
        "    self.embedder = EmbeddingModule(self.steganalysis_net)\n",
        "\n",
        "  def string_to_bits(self, message):\n",
        "    \"\"\"Convert a string to a sequence of bits.\"\"\"\n",
        "    return [int(bit) for bit in ''.join(format(ord(char), '08b') for char in message)]\n",
        "\n",
        "  def bits_to_string(self, bits):\n",
        "    \"\"\"Convert a sequence of bits to a string.\"\"\"\n",
        "    text = ''\n",
        "    for bit in range(0, len(bits), 8):\n",
        "      if bit + 8 <= len(bits):\n",
        "        byte = ''.join(str(bit) for bit in bits[bit:bit + 8])\n",
        "        text += chr(int(byte, 2))\n",
        "    return text\n",
        "\n",
        "  def compute_reward(self, detection_prob, snr, extraction_accuracy):\n",
        "    \"\"\"Compute reward for RL training\"\"\"\n",
        "    undetectability_reward = 1.0 - detection_prob\n",
        "    imperceptibility_reward = min(snr/ 50.0, 1.0) # normalize to [0, 1]\n",
        "\n",
        "    # weighted sum\n",
        "    total_reward = (\n",
        "        self.cfg.UNDETECTABILITY_WEIGHT * undetectability_reward +\n",
        "        self.cfg.IMPERCEPTIBILITY_WEIGHT * imperceptibility_reward +\n",
        "        self.cfg.EXTRACTION_ACCURACY_WEIGHT * extraction_accuracy\n",
        "    )\n",
        "    return total_reward\n",
        "\n",
        "  def embed_message(self, audio_path, message, output_path, model):\n",
        "    \"\"\"Embed a message into an audio file using trained policy\"\"\"\n",
        "    env = AudioStegoEnv(audio_path, message)\n",
        "    obs = env.reset()\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    self.modified_magnitudes = self.embedder.embed(self.magnitudes, self.mask, message, alpha=action[0])\n",
        "    stego_audio = self.preprocessor.reconstruct_audio(self.modified_magnitudes, self.phases)\n",
        "    # scipy.io.wavfile.write(output_path, SAMPLE_RATE, stego_audio)\n",
        "    self.preprocessor.save_audio(stego_audio,SAMPLE_RATE, output_path)\n",
        "    print(f\"Stego audio saved to {output_path}\")\n",
        "\n",
        "  def train_ppo(self, audio_path, message, total_timesteps=10000):\n",
        "    \"\"\"Train PPO agent for audio steganography\"\"\"\n",
        "    env = make_vec_env(lambda: AudioStegoEnv(audio_path, message), n_envs=4)\n",
        "\n",
        "    policy_kwargs = dict(\n",
        "        features_extractor_class=CustomFeatureExtractor,\n",
        "        features_extractor_kwargs=dict(features_dim=128),\n",
        "    )\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1,\n",
        "                device=device, learning_rate=3e-4, n_steps=1024)\n",
        "    model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    return model\n",
        "\n",
        "  def extract_message(self, stego_audio_path, msg_length):\n",
        "    \"\"\"Extract a message from a stego audio file\"\"\"\n",
        "    # stego_audio = self.preprocessor.load_audio(stego_audio_path)\n",
        "    # magnitudes, phases = self.preprocessor.compute_mdct()\n",
        "    # mask = self.preprocessor.get_non_critical_coeffs(magnitudes)\n",
        "    extracted_message = self.embedder.extract(self.modified_magnitudes, self.mask, msg_length)\n",
        "    return extracted_message\n",
        "\n",
        "  def plot_training_history(self):\n",
        "    \"\"\"Plot training metrics\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(self.training_history['rewards'], label='Reward')\n",
        "    plt.title('Training Rewards')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Average Reward')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KWcvIP6yRIBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MAIN EXECUTION SCRIPT ---"
      ],
      "metadata": {
        "id": "ULjz6C-CKiMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize the framework\n",
        "    cfg = Config()\n",
        "    framework = RLAudioSteganography(cfg)\n",
        "   # Load sample audio\n",
        "    audio_path = librosa.ex('trumpet')\n",
        "    output_path = \"output.wav\"\n",
        "    message = \"There are things that we do not wish to know. and this is a secret I want to send to you okay\"\n",
        "\n",
        "    # Initialize components\n",
        "    framework.Initialize_components(audio_path)\n",
        "\n",
        "    # Train PPO agent\n",
        "    print(\"Training PPO agent...\")\n",
        "    model = framework.train_ppo(audio_path, message, total_timesteps=10000)\n",
        "\n",
        "    framework.embed_message(audio_path, message, output_path, model)\n",
        "\n",
        "    # Visualize stego audio\n",
        "    # stego_preprocessor = AudioPreprocessor(audio_data=stego_audio, sr=SAMPLE_RATE)\n",
        "    # stego_preprocessor.plot_spectrogram(\"Stego Audio\")\n",
        "\n",
        "    # Extract message\n",
        "    extracted_message = framework.extract_message(output_path, len(message))\n",
        "    # extracted_message = embedder.extract(modified_magnitudes, mask, len(message))\n",
        "    print(f\"Original Message: {message}\")\n",
        "    print(f\"Extracted Message: {extracted_message}\")\n",
        "\n",
        "    # Evaluate performance\n",
        "    # Ensure both audio arrays have the same length for evaluation\n",
        "    # min_len = min(len(stego_audio), len(preprocessor.audio))\n",
        "    # stego_audio_trimmed = stego_audio[:min_len]\n",
        "    # original_audio_trimmed_eval = preprocessor.audio[:min_len]\n",
        "\n",
        "    # noise = stego_audio_trimmed - original_audio_trimmed_eval\n",
        "    # snr = 10 * np.log10(np.mean(original_audio_trimmed_eval**2) / np.mean(noise**2))\n",
        "    # print(f\"SNR: {snr:.2f} dB\")\n",
        "\n",
        "    # detection_prob = stego_system.detect(stego_audio)\n",
        "    # print(f\"Detection Probability: {detection_prob:.4f}\")\n",
        "    # print(f\"Undetectability: {100 * (1 - detection_prob):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srWhvcBg59Qv",
        "outputId": "18ce4204-6045-4dd9-e562-d95dea2774da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PPO agent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 10       |\n",
            "|    ep_rew_mean     | 10       |\n",
            "| time/              |          |\n",
            "|    fps             | 14       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 285      |\n",
            "|    total_timesteps | 4096     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 10           |\n",
            "|    ep_rew_mean          | 10           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 559          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033556535 |\n",
            "|    clip_fraction        | 0.00793      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.79         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | 4.35e-05     |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 5.21         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10          |\n",
            "|    ep_rew_mean          | 10          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 838         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003695189 |\n",
            "|    clip_fraction        | 0.0194      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.24        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00153    |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 6.96        |\n",
            "-----------------------------------------\n",
            "Stego audio saved to output.wav\n",
            "Original Message: There are things that we do not wish to know. and this is a secret I want to send to you okay\n",
            "Extracted Message: There are things that we do not wish to know. and this is a secret I want to send to you okay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eH9P_-wMHSiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}