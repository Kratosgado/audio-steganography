{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kratosgado/audio-steganography/blob/main/steg-ai/core_modules/Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QXp8Vn1BAu2P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3 shimmy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!git clone https://github.com/librosa/data.git ./audio_data\n",
        "# get audio files from librose\n",
        "audios_path = \"./audio_data/audio\"\n",
        "simple_audio_files = [os.path.join(audios_path, f) for f in os.listdir(audios_path) if f.endswith(\".ogg\")]\n",
        "complex_audio_files = [os.path.join(audios_path, f) for f in os.listdir(audios_path) if f.endswith(\".ogg\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3QaFlOkaE92",
        "outputId": "6470d581-58ce-4525-e24d-b4cbc615077d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './audio_data'...\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 156 (delta 61), reused 125 (delta 34), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (156/156), 14.78 MiB | 10.13 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.distributions import Normal\n",
        "from scipy.signal import get_window\n",
        "from scipy.fft import dct, idct\n",
        "import scipy.io.wavfile as wf\n",
        "import scipy\n",
        "import requests\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import random\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ],
      "metadata": {
        "id": "iZE9vuGCIj4l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "FRAME_SIZE = 1024 #2048\n",
        "HOP_LENGTH = 256 #512\n",
        "NON_CRITICAL_PERCENT = 0.1 # Modify bottom 10% of coeffs by magnitude\n",
        "STATE_DIM = 1024\n",
        "SAMPLE_RATE = 22050\n",
        "N_MELS = 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5uq1C49Mc3w",
        "outputId": "13f50f82-b755-41aa-ed34-882ee20c4ef3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- UTILITY FUNCTIONS ---"
      ],
      "metadata": {
        "id": "iNC_gfrXNLFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, local_filename): # gemini\n",
        "  \"\"\"Downloads a file if it doesn't already exist.\"\"\"\n",
        "  if not os.path.exists(local_filename):\n",
        "    print(f\"Downloading {local_filename}...\")\n",
        "    with requests.get(url, stream=True) as r:\n",
        "      r.raise_for_status()\n",
        "      with open(local_filename, 'wb') as f:\n",
        "        for chunk in r.iter_content(chunk_size=8192):\n",
        "          f.write(chunk)\n",
        "    print(f\"{local_filename} downloaded successfully.\")\n",
        "  else:\n",
        "    print(f\"{local_filename} already exists.\")\n",
        "\n",
        "NORM_NUM = 32768\n",
        "def textToBits( message):\n",
        "  return ''.join(format(ord(ch), '08b') for ch in message)\n",
        "\n",
        "\n",
        "def bitToChar(bits):\n",
        "  return chr(int(bits, 2))\n",
        "\n",
        "def textFromBits(bits):\n",
        "  text = ''\n",
        "  for bit in range(0, len(bits), 8):\n",
        "    text += bitToChar(bits[bit:bit + 8])\n",
        "  return text\n",
        "\n",
        "# Function to generate a random message (for the RL environment)\n",
        "def generate_random_message(length=50):\n",
        "    \"\"\"Generates a random string message.\"\"\"\n",
        "    import string\n",
        "    letters = string.ascii_letters + string.digits + string.punctuation + \" \"\n",
        "    return ''.join(random.choice(letters) for i in range(length))\n",
        "def extract_state(audio_segment, message_context, sr: int | float=44100):\n",
        "  # Audio features\n",
        "  mfcc = librosa.feature.mfcc(y=audio_segment, sr=sr)\n",
        "  spectral_centroid = librosa.feature.spectral_centroid(y=audio_segment, sr=sr)\n",
        "\n",
        "  # Temporal features\n",
        "  rms = librosa.feature.rms(y=audio_segment)\n",
        "  zcr = librosa.feature.zero_crossing_rate(y=audio_segment)\n",
        "\n",
        "  # Normalize and flatten features\n",
        "  return np.concatenate([mfcc.mean(axis=1),spectral_centroid.flatten(), rms.flatten(),zcr.flatten(),message_context ])\n",
        "\n",
        "def calculate_reward(stego_audio, original_audio, message, detection_prob):\n",
        "  # imperceptibility (audio quality)\n",
        "  psnr = 10 * np.log10(np.max(original_audio ** 2) / np.mean((original_audio - stego_audio) ** 2))\n",
        "\n",
        "  # message integrity\n",
        "  extracted = extract_message(stego_audio)\n",
        "  extracted = ''\n",
        "  ber = np.mean(extracted != message)\n",
        "\n",
        "  # capacity utilization\n",
        "  capacity_util = len(message) / max_possible_capacity\n",
        "\n",
        "  # steganalysis evasion\n",
        "  evasion_bonus = 1 - detection_prob\n",
        "\n",
        "  # combined reward\n",
        "  reward = (\n",
        "      0.4 * psnr / 30 + # normalized PSNR (target ~30dB)\n",
        "      0.3 * (1 - ber) + # BER penalty (message accuracy)\n",
        "      0.2 * capacity_util + # capacity utilization bonus\n",
        "      0.1 * evasion_bonus # steganalysis evasion bonus\n",
        "  )\n",
        "  return reward, {'psnr': psnr, 'ber': ber, 'capacity_util': capacity_util, 'evasion_bonus': evasion_bonus}\n",
        "\n",
        "class CustomLoggingCallback(BaseCallback):\n",
        "  \"\"\" A custom callback that logs additional information from the environment. \"\"\"\n",
        "  def __init__(self, verbose=0):\n",
        "    super(CustomLoggingCallback, self).__init__(verbose)\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    \"\"\"This method is called after each step in the environment.   \"\"\"\n",
        "    # Accessing environment infos from the VecEnv wrapper\n",
        "    if self.locals.get('infos'):\n",
        "      for info in self.locals['infos']:\n",
        "        # Ensure info is a dictionary and contains the required keys\n",
        "        if isinstance(info, dict) and 'snr' in info and 'detection_prob' in info:\n",
        "          self.logger.record('rollout/ep_snr', info['snr'])\n",
        "          self.logger.record('rollout/ep_reward', info['reward'])\n",
        "          self.logger.record('rollout/ep_extraction_accuracy', info['extraction_accuracy'])\n",
        "          self.logger.record('rollout/ep_detection_prob', info['detection_prob'])\n",
        "          self.logger.record('rollout/action', info['action'])\n",
        "    return True"
      ],
      "metadata": {
        "id": "_55FxjzNNKHD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- HYPERPARAMETERS ---"
      ],
      "metadata": {
        "id": "HV_OdAlXNoLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "  \"\"\"Class to hold all hyperparameters.\"\"\"\n",
        "  #Audio processing\n",
        "  FRAME_SIZE = 1024 #2048\n",
        "  HOP_LENGTH = 256 #512\n",
        "  NON_CRITICAL_PERCENT = 0.1 # Modify bottom 10% of coeffs by magnitude\n",
        "  STATE_DIM = 1024\n",
        "  SAMPLE_RATE = 22050\n",
        "  N_MELS = 128\n",
        "\n",
        "  # RL Training\n",
        "  EPISODES = 1000\n",
        "  LEARNING_RATE_ACTOR = 3e-4\n",
        "  LEARNING_RATE_CRITIC = 3e-4\n",
        "  GAMMA = 0.99 # Discount factor\n",
        "  GAE_LAMBDA = 0.95 # Lambda for Generalized Advantage Estimation\n",
        "  PPO_EPSILON = 0.2 # Epsilon for clipping in PPO\n",
        "  PPO_EPOCHS = 10 # Number of epochs for PPO update\n",
        "  BATCH_SIZE = 64\n",
        "\n",
        "  # Environment Network Pre-training\n",
        "  PRETRAIN_EPOCHS = 10\n",
        "  PRE_TRAIN_LR = 1e-3\n",
        "  PRE_TRAIN_BATCH_SIZE = 32\n",
        "\n",
        "  # Reward weights\n",
        "  SNR_WEIGHTS = 0.02 # Weight for SNR in reward. Tuned to be on a similar scale to detection prob.\n",
        "  DETECTION_WEIGHT = 1.0 # Weight for detection probability in reward.\n",
        "  IMPERCEPTIBILITY_WEIGHT = 0.3\n",
        "  UNDETECTABILITY_WEIGHT = 0.4\n",
        "  EXTRACTION_ACCURACY_WEIGHT = 0.3\n",
        "cfg = Config()"
      ],
      "metadata": {
        "id": "SLavUsivNtBI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 1: AUDIO PREPROCESSOR ---"
      ],
      "metadata": {
        "id": "W-feRKGXJB5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioPreprocessor:\n",
        "  \"\"\"Handles audio loading, MDCT, and inverse MDCT.\"\"\"\n",
        "  def __init__(self, audio_path= None, audio_data=None, frame_size=1024, hop_length=256, sr=22050):\n",
        "    if audio_path:\n",
        "      self.audio, self.sr = librosa.load(audio_path, sr=sr, mono=True)\n",
        "    elif audio_data is not None:\n",
        "      self.audio = audio_data\n",
        "      self.sr = sr\n",
        "    else:\n",
        "      raise ValueError(\"Either audio_path or audio_data must be provided\")\n",
        "\n",
        "    # Normalize audio\n",
        "    self.audio = self.audio / np.max(np.abs(self.audio))\n",
        "    self.frame_size = frame_size\n",
        "    self.hop_length = hop_length\n",
        "    self.window = get_window('hann', self.frame_size)\n",
        "    # return self.audio, self.sr\n",
        "\n",
        "  def load_audio(self, path):\n",
        "    \"\"\"Load WAV audio file\"\"\"\n",
        "    audio, _ = librosa.load(path, sr=self.sr)\n",
        "    return audio\n",
        "\n",
        "  def stft(self, audio):\n",
        "    \"\"\"Compute Short-Time Fourier Transform (STFT)\"\"\"\n",
        "    return librosa.stft(audio, n_fft=self.frame_size, hop_length=self.hop_length)\n",
        "\n",
        "  def istft(self, stft_matrix):\n",
        "    \"\"\"Compute Inverse Short-Time Fourier Transform (ISTFT)\"\"\"\n",
        "    return librosa.istft(stft_matrix, hop_length=self.hop_length)\n",
        "\n",
        "  def compute_mdct(self):\n",
        "    \"\"\"Compute Modified Discrete Cosine Transform (MDCT) using STFT and DCT from librosa\"\"\"\n",
        "    stft = self.stft(self.audio)\n",
        "    magnitudes = np.abs(stft)\n",
        "    phases = np.angle(stft)\n",
        "    return magnitudes, phases\n",
        "\n",
        "  def get_non_critical_coeffs(self, magnitudes, percentile=10):\n",
        "    \"\"\"Identify non-critical coefficients (lowest magnitude)\"\"\"\n",
        "    threshold = np.percentile(np.abs(magnitudes.flatten()), percentile)\n",
        "    mask = np.abs(magnitudes) < threshold\n",
        "    return mask\n",
        "\n",
        "  def reconstruct_audio(self, magnitudes, phases):\n",
        "    \"\"\"Reconstruct audio from magnitude/stft matrix and phase/non_critical_coeffs\"\"\"\n",
        "    stft = magnitudes * np.exp(1j * phases)\n",
        "    reconstructed_audio = self.istft(stft)\n",
        "    return reconstructed_audio\n",
        "\n",
        "  def plot_spectrogram(self, title):\n",
        "    \"\"\"Visualize audio spectrogram\"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    S = librosa.amplitude_to_db(np.abs(librosa.stft(self.audio)), ref=np.max)\n",
        "    librosa.display.specshow(S, sr=self.sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "  def save_audio(self, audio: np.ndarray, sr: int, path: str):\n",
        "    wf.write(path,sr, (audio * NORM_NUM).astype(np.int16))"
      ],
      "metadata": {
        "id": "z-rBWB4UJAyM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 5: EMBEDDING/EXTRACTION MODULE ---\n",
        "Main Sign encoding class"
      ],
      "metadata": {
        "id": "hyIIZSInKMwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class EmbeddingModule(ABC):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def embed(self, *args, **kwargs):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def extract(self, *args, **kwargs) -> str:\n",
        "    pass\n",
        "\n",
        "class SignEncoding(EmbeddingModule):\n",
        "  \"\"\"Embeds and extracts messages from MDCT coefficients.\"\"\"\n",
        "  def __init__(self, steganalysis_net=None, method='mdct'):\n",
        "        self.steganalysis_net = steganalysis_net\n",
        "        if self.steganalysis_net:\n",
        "            self.steganalysis_net.to(device)\n",
        "            self.steganalysis_net.eval()\n",
        "\n",
        "  def embed(self, magnitudes, mask, bin_message: list[int], alpha=0.01):\n",
        "    \"\"\"Embed message using sign encoding in non-critical coefficients\"\"\"\n",
        "    # Apply mask to get non-critical coefficients\n",
        "    coeffs = magnitudes.copy()\n",
        "    non_critical = coeffs[mask]\n",
        "\n",
        "    # Ensure we have enough coefficients for the message\n",
        "    if len(non_critical) < len(bin_message):\n",
        "        raise ValueError(\"Message too long for available non-critical coefficients\")\n",
        "\n",
        "    # Embed message using sign encoding\n",
        "    for i, bit in enumerate(bin_message):\n",
        "        sign = 1 if bit == 1 else -1\n",
        "        non_critical[i] = sign * np.abs(non_critical[i]) * (1 + alpha)\n",
        "\n",
        "    # Update coefficients\n",
        "    coeffs[mask] = non_critical\n",
        "    return coeffs\n",
        "\n",
        "  def extract(self, magnitudes, mask, message_length):\n",
        "    \"\"\"Extract message from non-critical coefficients\"\"\"\n",
        "    # Apply mask to get non-critical coefficients\n",
        "    non_critical = magnitudes[mask]\n",
        "\n",
        "    # Extract message from sign\n",
        "    bin_message = []\n",
        "    for i in range(message_length * 8):\n",
        "        sign = 1 if non_critical[i] >= 0 else -1\n",
        "        bit = 1 if sign > 0 else 0\n",
        "        bin_message.append(str(bit))\n",
        "\n",
        "    # Convert binary to string\n",
        "    bin_str = ''.join(bin_message)\n",
        "    chars = [chr(int(bin_str[i:i+8], 2)) for i in range(0, len(bin_str), 8)]\n",
        "    return ''.join(chars)\n",
        "\n",
        "  def detect(self, audio):\n",
        "    \"\"\"Compute detection probability using steganalysis network\"\"\"\n",
        "    if not self.steganalysis_net:\n",
        "      raise ValueError(\"Steganalysis network not initialized\")\n",
        "\n",
        "    # Convert to tensor\n",
        "    audio_tensor = torch.as_tensor(audio, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prob = self.steganalysis_net(audio_tensor).item()\n",
        "    return prob"
      ],
      "metadata": {
        "id": "bc5xRFmqKK_m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spread Spectrum"
      ],
      "metadata": {
        "id": "hmFr72llR9ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpreadSpectrum(EmbeddingModule):\n",
        "  def __init__(self, carrier_freq=10000, chip_rate=100, snr=20):\n",
        "    \"\"\"\n",
        "    Initialize the steganography system\n",
        "\n",
        "    Parameters:\n",
        "      carrier_freq (int): Carrier frequency in Hz for embedding\n",
        "      chip_rate (int): How many samples per bit (spreading factor)\n",
        "      snr (int): Desired Signal to noise ratio in dB for embedding\n",
        "    \"\"\"\n",
        "    self.carrier_freq = carrier_freq\n",
        "    self.chip_rate = chip_rate\n",
        "    self.snr_db = snr\n",
        "    self.sample_rate = 4100 # standard audio sample rate\n",
        "\n",
        "    # Parameters for Gold sequence generation (example values)\n",
        "    self.taps1 = [5, 2]\n",
        "    self.taps2 = [5, 4, 2, 1] # Must be a preferred pair with taps1\n",
        "    self.seed1 = 0b11111\n",
        "    self.seed2 = 0b10101\n",
        "\n",
        "\n",
        "  def _generate_m_sequence(self, taps, length, initial_state):\n",
        "      \"\"\"Generate an m-sequence.\"\"\"\n",
        "      lfsr = initial_state\n",
        "      seq = np.zeros(length)\n",
        "      # mask = sum(1 << (t - 1) for t in taps) # Mask is not used in this implementation\n",
        "\n",
        "      for i in range(length):\n",
        "          seq[i] = 1 if (lfsr & 1) else -1  # Convert to bipolar (-1, 1)\n",
        "          feedback = 0\n",
        "          for tap in taps:\n",
        "              feedback ^= (lfsr >> (tap - 1)) & 1\n",
        "          # Adjust the shift based on the number of bits in the initial state\n",
        "          lfsr = (lfsr >> 1) | (feedback << (len(bin(initial_state)) - 3)) # Assuming initial_state is not 0\n",
        "\n",
        "      return seq\n",
        "\n",
        "  def _generate_spreading_code(self, length):\n",
        "      \"\"\"Generate a Gold sequence.\"\"\"\n",
        "      # The lengths of the m-sequences must be the same\n",
        "      # and derived from the same primitive polynomial.\n",
        "      # The taps define the primitive polynomials.\n",
        "      # The seeds are the initial states of the LFSRs.\n",
        "\n",
        "      m_seq1 = self._generate_m_sequence(self.taps1, length, self.seed1)\n",
        "      m_seq2 = self._generate_m_sequence(self.taps2, length, self.seed2)\n",
        "\n",
        "      # XOR the two m-sequences\n",
        "      gold_seq = m_seq1 * m_seq2 # For bipolar sequences, XOR is multiplication\n",
        "\n",
        "      return gold_seq\n",
        "\n",
        "\n",
        "  def _calculate_required_bandwidth(self, message_length):\n",
        "    \"\"\"Calculate the required bandwidth based on message length.\"\"\"\n",
        "    # each bit is spread over chip_rate samples\n",
        "    return message_length * self.chip_rate\n",
        "\n",
        "  def embed(self, audio_path, message, output_path):\n",
        "    \"\"\"\n",
        "    Embed a message into an audio file.\n",
        "\n",
        "    Parameters:\n",
        "      audio_path (str): Path to the audio file.\n",
        "      message (str): The message to be embedded.\n",
        "      output_path (str): Path to save the embedded audio file.\n",
        "    \"\"\"\n",
        "    # load audio file\n",
        "    original_audio, sr = librosa.load(audio_path, sr=self.sample_rate)\n",
        "\n",
        "    # convert message to binary\n",
        "    message_bin = textToBits(message)\n",
        "    message_bin = np.array([int(b) for b in message_bin], dtype=np.float32)\n",
        "    message_bin = message_bin * 2 - 1 # convert to bipoloar (-1, 1)\n",
        "\n",
        "    # generate spreading codes\n",
        "    code_length  = len(message_bin) * self.chip_rate\n",
        "    # spreading_code = self._generate_spreading_code(code_length, seed=42) # Old simplified code\n",
        "    spreading_code = self._generate_spreading_code(code_length)\n",
        "\n",
        "\n",
        "    # create the spread message signal\n",
        "    spread_message = np.repeat(message_bin, self.chip_rate) * spreading_code\n",
        "\n",
        "    # create carrier signal (sine wave at carrier frequency)\n",
        "    t = np.arange(len(spread_message)) / sr\n",
        "    carrier = np.sin(2 * np.pi * self.carrier_freq * t)\n",
        "\n",
        "    # modulate the message onto the carrier\n",
        "    modulated = spread_message * carrier\n",
        "\n",
        "    # adjust the signal power based on desired snr\n",
        "    signal_power = np.var(original_audio)\n",
        "    message_power = np.var(modulated)\n",
        "    desired_message_power = signal_power/ (10 ** (self.snr_db / 10))\n",
        "    scaling_factor = np.sqrt(desired_message_power / message_power)\n",
        "    modulated = modulated * scaling_factor\n",
        "\n",
        "    # pad or truncate the modulated signal to match audio length\n",
        "    if len(modulated) < len(original_audio):\n",
        "      modulated = np.pad(modulated, (0, len(original_audio) - len(modulated)), 'constant')\n",
        "    else:\n",
        "      modulated = modulated[:len(original_audio)]\n",
        "\n",
        "    # embed the message into the audio\n",
        "    stego_audio = original_audio + modulated\n",
        "\n",
        "    sf.write(output_path, stego_audio, sr)  # save the stego audio\n",
        "    return stego_audio\n",
        "\n",
        "  def extract(self, stego_path, message_length, original_audio_path=None):\n",
        "    \"\"\"\n",
        "        Extract a hidden message from a stego audio file.\n",
        "\n",
        "        Parameters:\n",
        "            stego_path (str): Path to the stego audio file\n",
        "            message_length (int): Length of the hidden message in bits\n",
        "            original_audio_path (str): Optional path to original audio for comparison\n",
        "        \"\"\"\n",
        "    # load stego audio\n",
        "    y_stego, sr = librosa.load(stego_path, sr=self.sample_rate)\n",
        "\n",
        "    # if original audio is provided, subtract it to get just the message\n",
        "    if original_audio_path:\n",
        "      y_original, _ = librosa.load(original_audio_path, sr=self.sample_rate)\n",
        "      y_diff = y_stego - y_original\n",
        "    else:\n",
        "      y_diff = y_stego\n",
        "\n",
        "    # generate the same spreading code used in embedding\n",
        "    code_length = message_length * 8 * self.chip_rate # 8 bits per character\n",
        "    # spreading_code = self._generate_spreading_code(code_length, seed=42) # Old simplified code\n",
        "    spreading_code = self._generate_spreading_code(code_length)\n",
        "\n",
        "\n",
        "    # create carrier signal\n",
        "    t = np.arange(len(spreading_code)) / sr\n",
        "    carrier = np.sin(2 * np.pi * self.carrier_freq * t)\n",
        "\n",
        "    # pad or truncate the carrier to match the difference signal\n",
        "    if len(carrier) < len(y_diff):\n",
        "      carrier = np.pad(carrier, (0, len(y_diff) - len(carrier)), 'constant')\n",
        "    else:\n",
        "      carrier = carrier[:len(y_diff)]\n",
        "\n",
        "    # demodulate the signal\n",
        "    demodulated = y_diff * carrier\n",
        "\n",
        "    # correlate with spreading code to extract bits\n",
        "    extracted_bits = ''\n",
        "    for i in range(message_length * 8):\n",
        "      start = i * self.chip_rate\n",
        "      end = start + self.chip_rate\n",
        "      if end > len(demodulated):\n",
        "        break\n",
        "      segment = demodulated[start:end]\n",
        "      code_segment = spreading_code[start:end]\n",
        "\n",
        "      # calculate correlation\n",
        "      correlation = np.sum(segment * code_segment)\n",
        "      extracted_bits += ('1' if correlation > 0 else '0')\n",
        "\n",
        "    # convert bits to string\n",
        "    return extracted_bits"
      ],
      "metadata": {
        "id": "Iv0zqtkMSArs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 2: RL ACTOR-CRITIC NETWORKS ---"
      ],
      "metadata": {
        "id": "wfre1MB1Julg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "  \"\"\"Actor Network: Decides on the modification scale.\"\"\"\n",
        "  def __init__(self, input_dim, hidden_dim=256):\n",
        "    super(PolicyNetwork, self).__init__()\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.mean_layer = nn.Linear(hidden_dim, 1)\n",
        "    self.log_std_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    features = self.fc(x)\n",
        "    mean = self.mean_layer(features)\n",
        "    log_std = self.log_std_layer(features)\n",
        "    log_std = torch.clamp(log_std, min=-20, max=2)  # Constrain for stability\n",
        "    return mean, log_std\n",
        "\n",
        "  def sample_action(self, state):\n",
        "    \"\"\"Sample action from policy distribution\"\"\"\n",
        "    state_tensor = torch.as_tensor(state, dtype=torch.float32).to(device)\n",
        "    mean, log_std = self.forward(state_tensor)\n",
        "    std = torch.exp(log_std)\n",
        "    normal_dist = torch.distributions.Normal(mean, std)\n",
        "    action = normal_dist.sample()\n",
        "    return action.cpu().detach().numpy().flatten()\n",
        "\n",
        "# 7. Feature Extractor for PPO\n",
        "class CustomFeatureExtractor(BaseFeaturesExtractor):\n",
        "  def __init__(self, observation_space: spaces.Box, features_dim = 128):\n",
        "    super().__init__(observation_space, features_dim)\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(observation_space.shape[0], 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, features_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
        "    return self.net(observations)"
      ],
      "metadata": {
        "id": "UmJ4bvTvJeK2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -- Action and Observation Spaces --"
      ],
      "metadata": {
        "id": "gsPS0n37ZcXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionSpace(gym.Space):\n",
        "  def __init__(self):\n",
        "    # Define the bounds for continuous actions\n",
        "    self.continuous_bounds = np.array([\n",
        "        [5000, 15000], # carrier frequency\n",
        "        [50, 200], # chip rate\n",
        "        [10, 30] # snr\n",
        "    ], dtype=np.float32) # Specify dtype as float32\n",
        "\n",
        "    # Define the number of discrete options\n",
        "    self.discrete_options = 3 # band selection options\n",
        "\n",
        "    # Define the action space as a Tuple of Box and Discrete spaces\n",
        "    self.spaces = (\n",
        "        gym.spaces.Box(low=self.continuous_bounds[:, 0], high=self.continuous_bounds[:, 1], dtype=np.float32),\n",
        "        gym.spaces.Discrete(self.discrete_options)\n",
        "    )\n",
        "\n",
        "    # Initialize the parent class\n",
        "    super().__init__(None, None) # Bounds and dtype are defined by the spaces\n",
        "\n",
        "  def sample(self):\n",
        "    # Sample from the continuous and discrete spaces\n",
        "    cont = self.spaces[0].sample()\n",
        "    disc = self.spaces[1].sample()\n",
        "    # Return the sample as a tuple, matching the structure of the spaces\n",
        "    return (cont, disc)\n",
        "\n",
        "  def contains(self, x):\n",
        "    # Check if an action is within the space\n",
        "    if not isinstance(x, tuple) or len(x) != 2:\n",
        "        return False\n",
        "    return self.spaces[0].contains(x[0]) and self.spaces[1].contains(x[1])\n",
        "\n",
        "  def __repr__(self):\n",
        "        return \"SteganographyActionSpace\"\n",
        "\n",
        "  def __eq__(self, other):\n",
        "        return isinstance(other, ActionSpace)"
      ],
      "metadata": {
        "id": "s9Rvs0CBZhVj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MODULE 3: ENVIRONMENT NETWORK (STEGANALYZER) ---"
      ],
      "metadata": {
        "id": "EH5KOS4wJw0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SteganalysisCNN(nn.Module):\n",
        "  \"\"\"A 1D CNN that acts as a steganalysis tool.\"\"\"\n",
        "  def __init__(self, input_channels=1):\n",
        "    super(SteganalysisCNN, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv1d(input_channels, 32, kernel_size=5, stride=2, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=2),\n",
        "        nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(kernel_size=2),\n",
        "        nn.Flatten()\n",
        "    )\n",
        "\n",
        "    # Calculate output dimension after convolutions\n",
        "    test_input = torch.randn(1, input_channels, 500)\n",
        "    conv_output_dim = self.conv(test_input).shape[-1]\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(conv_output_dim, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return self.fc(x)\n",
        "\n",
        " #5. Custom Gym Environment for RL Training\n",
        "class AudioStegoEnv(gym.Env):\n",
        "  def __init__(self, audio_path, bin_message: list[int], method=\"sign-encoding\"):\n",
        "    super(AudioStegoEnv, self).__init__()\n",
        "\n",
        "    # Initialize audio and message\n",
        "    self.preprocessor = AudioPreprocessor(audio_path=audio_path)\n",
        "    self.original_audio = self.preprocessor.audio.copy()\n",
        "    self.bin_message = bin_message\n",
        "    self.message_length = len(bin_message) // 8  # Store message length in characters\n",
        "\n",
        "    # Compute initial features\n",
        "    magnitudes, _ = self.preprocessor.compute_mdct()\n",
        "    self.mask = self.preprocessor.get_non_critical_coeffs(magnitudes)\n",
        "\n",
        "    # Define action and observation spaces\n",
        "    self.action_space = spaces.Box(low=0.0, high=0.1, shape=(1,), dtype=np.float32)\n",
        "    self.observation_space = spaces.Box(low=-1.0, high=1.0,\n",
        "                                        shape=(N_MELS,), dtype=np.float32)\n",
        "    self.embedder: EmbeddingModule = SignEncoding() if method == \"sign-encoding\" else SpreadSpectrum()\n",
        "\n",
        "    # Initialize state\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    \"\"\"Reset environment to initial state\"\"\"\n",
        "    super().reset(seed=seed) # Call the parent class reset with seed\n",
        "\n",
        "    self.current_audio = self.original_audio.copy()\n",
        "    self.current_step = 0\n",
        "    return self._get_obs(), {} # Return observation and info dictionary\n",
        "\n",
        "  def _get_obs(self):\n",
        "    \"\"\"Extract MFCC features as observation\"\"\"\n",
        "    mfcc = librosa.feature.mfcc(y=self.current_audio, sr=SAMPLE_RATE,\n",
        "                                n_mfcc=N_MELS, n_fft=FRAME_SIZE,\n",
        "                                hop_length=HOP_LENGTH)\n",
        "    return np.mean(mfcc, axis=1)\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Execute one embedding step\"\"\"\n",
        "    alpha = action[0]\n",
        "\n",
        "    # Compute MDCT\n",
        "    magnitudes, phases = self.preprocessor.compute_mdct()\n",
        "\n",
        "    # Embed message\n",
        "    modified_magnitudes = self.embedder.embed(magnitudes, self.mask, self.bin_message, alpha)\n",
        "\n",
        "    # Reconstruct audio\n",
        "    self.current_audio = self.preprocessor.reconstruct_audio(modified_magnitudes, phases)\n",
        "\n",
        "    # Compute rewards\n",
        "    snr = self._calculate_snr()\n",
        "    detection_prob = self._simulate_detection()\n",
        "    extraction_accuracy = self._calculate_extraction_accuracy(modified_magnitudes)\n",
        "    reward = self._calculate_reward(snr, detection_prob, extraction_accuracy)\n",
        "\n",
        "    # Update state\n",
        "    self.current_step += 1\n",
        "    done = self.current_step >= 10  # Train for 10 steps\n",
        "    info = {\n",
        "        \"snr\": snr,\n",
        "        \"detection_prob\": detection_prob,\n",
        "        \"extraction_accuracy\": extraction_accuracy,\n",
        "        \"reward\": reward,\n",
        "        \"action\": action\n",
        "    }\n",
        "    return self._get_obs(), reward, done, False, info\n",
        "\n",
        "  def _calculate_snr(self):\n",
        "    \"\"\"Calculate Signal-to-Noise Ratio\"\"\"\n",
        "    # Ensure both audio arrays have the same length before calculating noise\n",
        "    min_len = min(len(self.current_audio), len(self.original_audio))\n",
        "    current_audio_trimmed = self.current_audio[:min_len]\n",
        "    original_audio_trimmed = self.original_audio[:min_len]\n",
        "\n",
        "    noise = current_audio_trimmed - original_audio_trimmed\n",
        "    signal_power = np.mean(original_audio_trimmed ** 2)\n",
        "    noise_power = np.mean(noise ** 2)\n",
        "\n",
        "    if noise_power == 0:\n",
        "        return 100  # High SNR if no noise\n",
        "\n",
        "    return 10 * np.log10(signal_power / noise_power)\n",
        "\n",
        "  def _simulate_detection(self):\n",
        "    \"\"\"Simulate steganalysis detection\"\"\"\n",
        "    # not real\n",
        "    snr = self._calculate_snr()\n",
        "    return 1 / (1 + np.exp(0.5 * (snr - 50)))  # Logistic function\n",
        "\n",
        "  def _calculate_extraction_accuracy(self, modified_magnitudes):\n",
        "    \"\"\"Calculate the accuracy of extracted bits\"\"\"\n",
        "    # Use the same mask as embedding for extraction simulation\n",
        "    extracted_bits_str = self.embedder.extract(modified_magnitudes, self.mask, self.message_length)\n",
        "    extracted_bits = [int(bit) for bit in ''.join(format(ord(char), '08b') for char in extracted_bits_str)]\n",
        "\n",
        "    # Compare with original binary message\n",
        "    correct_bits = sum(1 for i in range(min(len(extracted_bits), len(self.bin_message))) if extracted_bits[i] == self.bin_message[i])\n",
        "    total_bits = len(self.bin_message)\n",
        "    return correct_bits / total_bits if total_bits > 0 else 0.0\n",
        "\n",
        "  def _calculate_reward(self, snr, detection_prob, extraction_accuracy):\n",
        "    \"\"\"Calculate reward balancing SNR, detectability, and extraction accuracy\"\"\"\n",
        "    # Target: SNR > 50 dB, detection_prob < 0.1, extraction_accuracy close to 1.0\n",
        "    snr_reward = min(snr / 50, 1.0)\n",
        "    detect_reward = 1.0 - min(detection_prob, 1.0)\n",
        "\n",
        "    # Weighted combination\n",
        "    return (\n",
        "        cfg.SNR_WEIGHTS * snr_reward +\n",
        "        cfg.DETECTION_WEIGHT * detect_reward +\n",
        "        cfg.EXTRACTION_ACCURACY_WEIGHT * extraction_accuracy\n",
        "    )"
      ],
      "metadata": {
        "id": "Vk-lzxwRJt0P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -- MAIN FRAMEWORK --"
      ],
      "metadata": {
        "id": "A69oR2apRBwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RLAudioSteganography:\n",
        "  \"\"\"Main framework class\"\"\"\n",
        "  def __init__(self, cfg: Config) -> None:\n",
        "    self.cfg = cfg\n",
        "    self.embedded_mask = None # Store the mask used during embedding\n",
        "    self.original_magnitudes = None # Store original magnitudes\n",
        "\n",
        "  def Initialize_components(self, audio_path, method=\"sign-encoding\"):\n",
        "    \"\"\"Initialize components\"\"\"\n",
        "    self.preprocessor = AudioPreprocessor(audio_path=audio_path)\n",
        "    self.original_magnitudes, self.phases = self.preprocessor.compute_mdct()\n",
        "    self.mask = self.preprocessor.get_non_critical_coeffs(self.original_magnitudes)\n",
        "    self.steganalysis_net = SteganalysisCNN()\n",
        "    # self.steganalysis_net = SteganalysisCNN(input_channels=len(self.preprocessor.audio))\n",
        "    self.steganalysis_net.to(device)\n",
        "    self.embedder: EmbeddingModule = SignEncoding() if method == \"sign-encoding\" else SpreadSpectrum()\n",
        "\n",
        "  def string_to_bits(self, message):\n",
        "    \"\"\"Convert a string to a sequence of bits.\"\"\"\n",
        "    return [int(bit) for bit in ''.join(format(ord(char), '08b') for char in message)]\n",
        "\n",
        "  def bits_to_string(self, bits):\n",
        "    \"\"\"Convert a sequence of bits to a string.\"\"\"\n",
        "    text = ''\n",
        "    for bit in range(0, len(bits), 8):\n",
        "      if bit + 8 <= len(bits):\n",
        "        byte = ''.join(str(bit) for bit in bits[bit:bit + 8])\n",
        "        text += chr(int(byte, 2))\n",
        "    return text\n",
        "\n",
        "  def compute_reward(self, detection_prob, snr, extraction_accuracy):\n",
        "    \"\"\"Compute reward for RL training\"\"\"\n",
        "    undetectability_reward = 1.0 - detection_prob\n",
        "    imperceptibility_reward = min(snr/ 50.0, 1.0) # normalize to [0, 1]\n",
        "\n",
        "    # weighted sum\n",
        "    total_reward = (\n",
        "        self.cfg.UNDETECTABILITY_WEIGHT * undetectability_reward +\n",
        "        self.cfg.IMPERCEPTIBILITY_WEIGHT * imperceptibility_reward +\n",
        "        self.cfg.EXTRACTION_ACCURACY_WEIGHT * extraction_accuracy\n",
        "    )\n",
        "    return total_reward\n",
        "\n",
        "  def train_ppo(self, audio_path, message, total_timesteps=10000)-> PPO:\n",
        "    \"\"\"Train PPO agent for audio steganography\"\"\"\n",
        "    env = make_vec_env(lambda: AudioStegoEnv(audio_path, self.string_to_bits(message)), n_envs=4)\n",
        "\n",
        "    policy_kwargs = dict(\n",
        "        features_extractor_class=CustomFeatureExtractor,\n",
        "        features_extractor_kwargs=dict(features_dim=128),\n",
        "    )\n",
        "\n",
        "    model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1,\n",
        "                device=device, learning_rate=self.cfg.LEARNING_RATE_ACTOR, n_steps=self.cfg.EPISODES)\n",
        "    # Instantiate the custom callback\n",
        "    custom_callback = CustomLoggingCallback()\n",
        "    model.learn(total_timesteps, custom_callback)\n",
        "\n",
        "    return model\n",
        "\n",
        "  def embed_message(self, audio_path, message, output_path, model):\n",
        "    \"\"\"Embed a message into an audio file using trained policy\"\"\"\n",
        "    # Re-initialize preprocessor and compute magnitudes/phases/mask for the specific audio being embedded into\n",
        "    self.preprocessor = AudioPreprocessor(audio_path=audio_path)\n",
        "    self.original_magnitudes, self.phases = self.preprocessor.compute_mdct()\n",
        "    self.mask = self.preprocessor.get_non_critical_coeffs(self.original_magnitudes)\n",
        "    self.embedded_mask = self.mask # Store the mask used for embedding\n",
        "\n",
        "    # Steganalysis network is initialized in Initialize_components, ensure it's done before embedding\n",
        "    # If embed_message is called standalone, ensure Initialize_components is called first with the correct audio_path\n",
        "\n",
        "    env = AudioStegoEnv(audio_path, self.string_to_bits(message)) # Use the correct audio_path and message\n",
        "    obs, info = env.reset()\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    # Convert message string to bits for embedding\n",
        "    message_bits = self.string_to_bits(message)\n",
        "    self.modified_magnitudes = self.embedder.embed(self.original_magnitudes, self.embedded_mask, message_bits, alpha=action[0])\n",
        "    stego_audio = self.preprocessor.reconstruct_audio(self.modified_magnitudes, self.phases)\n",
        "    self.preprocessor.save_audio(stego_audio,SAMPLE_RATE, output_path)\n",
        "    print(f\"Stego audio saved to {output_path}\")\n",
        "\n",
        "\n",
        "  def extract_message(self, stego_audio_path, msg_length):\n",
        "    \"\"\"Extract a message from a stego audio file\"\"\"\n",
        "    # Load the stego audio\n",
        "    preprocessor_stego = AudioPreprocessor(audio_path=stego_audio_path)\n",
        "    magnitudes_stego, phases_stego = preprocessor_stego.compute_mdct()\n",
        "\n",
        "    # Use the stored mask from embedding for extraction\n",
        "    if self.embedded_mask is None:\n",
        "        raise ValueError(\"Embedding must be performed before extraction to get the mask.\")\n",
        "\n",
        "    # Use the embedder to extract\n",
        "    # The embedder's extract method requires the magnitudes from the stego audio,\n",
        "    # the stored mask, and the original message length in characters.\n",
        "    extracted_message = self.embedder.extract(self.modified_magnitudes, self.embedded_mask, msg_length)\n",
        "    return extracted_message\n",
        "\n",
        "\n",
        "  def plot_training_history(self):\n",
        "    \"\"\"Plot training metrics\"\"\"\n",
        "    # plt.figure(figsize=(12, 8))\n",
        "    # plt.subplot(2, 2, 1)\n",
        "    # plt.plot(self.training_history['rewards'], label='Reward')\n",
        "    # plt.title('Training Rewards')\n",
        "    # plt.xlabel('Episode')\n",
        "    # plt.ylabel('Average Reward')\n",
        "    # plt.legend()\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "KWcvIP6yRIBc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- MAIN EXECUTION SCRIPT ---"
      ],
      "metadata": {
        "id": "ULjz6C-CKiMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize the framework\n",
        "    cfg = Config()\n",
        "    framework = RLAudioSteganography(cfg)\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    # Load sample audio for training\n",
        "    training_audio_path = librosa.ex('trumpet')\n",
        "    message_to_embed = \"There are things that we do not wish to know. and this is a secret I want to send to you okay\"\n",
        "\n",
        "    # Initialize components with the training audio\n",
        "    framework.Initialize_components(training_audio_path)\n",
        "\n",
        "    # Train PPO agent\n",
        "    print(\"Training PPO agent...\")\n",
        "    model = framework.train_ppo(training_audio_path, message_to_embed, total_timesteps=100)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = \"ppo_audio_stego_model\"\n",
        "    model.save(model_save_path)\n",
        "    print(f\"Trained model saved to {model_save_path}\")\n",
        "\n",
        "    # --- Embedding with the Trained Model on a New Audio ---\n",
        "    print(\"\\nEmbedding message in a new audio file using the trained model...\")\n",
        "\n",
        "    # Load the saved model\n",
        "    loaded_model = PPO.load(model_save_path)\n",
        "    print(f\"Loaded model from {model_save_path}\")\n",
        "\n",
        "    # Define a new audio file and output path\n",
        "    new_audio_path = librosa.ex('trumpet', hq=True) # Using a different trumpet example\n",
        "    new_output_path = \"stego_new_audio.wav\"\n",
        "\n",
        "    # Initialize components with the *new* audio\n",
        "    framework.Initialize_components(new_audio_path)\n",
        "\n",
        "    # Embed message using the loaded model\n",
        "    framework.embed_message(new_audio_path, message_to_embed, new_output_path, loaded_model)\n",
        "\n",
        "    # Extract message from the new stego audio\n",
        "    extracted_message = framework.extract_message(new_output_path, len(message_to_embed))\n",
        "    print(f\"\\nOriginal Message: {message_to_embed}\")\n",
        "    print(f\"Extracted Message from new audio: {extracted_message}\")\n",
        "\n",
        "    # --- Evaluation (Optional) ---\n",
        "    # You can add evaluation steps here similar to the commented out code\n",
        "    # to check SNR and detection probability on the new stego audio."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srWhvcBg59Qv",
        "outputId": "562c393b-d258-4eaa-d0c1-34b1e31438fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'sorohanro_-_solo-trumpet-06.ogg' from 'https://librosa.org/data/audio/sorohanro_-_solo-trumpet-06.ogg' to '/root/.cache/librosa'.\n",
            "/usr/local/lib/python3.11/dist-packages/audioread/rawread.py:16: DeprecationWarning: 'aifc' is deprecated and slated for removal in Python 3.13\n",
            "  import aifc\n",
            "/usr/local/lib/python3.11/dist-packages/audioread/rawread.py:17: DeprecationWarning: 'audioop' is deprecated and slated for removal in Python 3.13\n",
            "  import audioop\n",
            "/usr/local/lib/python3.11/dist-packages/audioread/rawread.py:19: DeprecationWarning: 'sunau' is deprecated and slated for removal in Python 3.13\n",
            "  import sunau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PPO agent...\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4000`, after every 62 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=1000 and n_envs=4)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "| rollout/                  |              |\n",
            "|    action                 | [0.1]        |\n",
            "|    ep_detection_prob      | 3.365486e-17 |\n",
            "|    ep_extraction_accuracy | 1            |\n",
            "|    ep_len_mean            | 10           |\n",
            "|    ep_rew_mean            | 13.2         |\n",
            "|    ep_reward              | 1.3199999    |\n",
            "|    ep_snr                 | 125.86075    |\n",
            "| time/                     |              |\n",
            "|    fps                    | 17           |\n",
            "|    iterations             | 1            |\n",
            "|    time_elapsed           | 223          |\n",
            "|    total_timesteps        | 4000         |\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Downloading file 'sorohanro_-_solo-trumpet-06.hq.ogg' from 'https://librosa.org/data/audio/sorohanro_-_solo-trumpet-06.hq.ogg' to '/root/.cache/librosa'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model saved to ppo_audio_stego_model\n",
            "\n",
            "Embedding message in a new audio file using the trained model...\n",
            "Loaded model from ppo_audio_stego_model\n",
            "Stego audio saved to stego_new_audio.wav\n",
            "\n",
            "Original Message: There are things that we do not wish to know. and this is a secret I want to send to you okay\n",
            "Extracted Message from new audio: There are things that we do not wish to know. and this is a secret I want to send to you okay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config()\n",
        "framework_test = RLAudioSteganography(cfg)\n",
        "\n",
        "audio = '/content/drive/MyDrive/Colab Notebooks/steganography/input.wav'\n",
        "message = \"\"\"\n",
        "    Embed a message into an audio file.\n",
        "\n",
        "    Parameters:\n",
        "      audio_path (str): Path to the audio file.\n",
        "      message (str): The message to be embedded.\n",
        "      output_path (str): Path to save the embedded audio file.\n",
        "    \"\"\"\n",
        "output_path = \"test.wav\"\n",
        "\n",
        "framework_test.Initialize_components(audio_path=audio)\n",
        "# Load the saved model\n",
        "model_test = PPO.load(model_save_path)\n",
        "print(f\"Loaded model from {model_save_path}\")\n",
        "# Embed message using the loaded model\n",
        "framework_test.embed_message(audio, message, output_path, model_test)\n",
        "\n",
        "# Extract message from the new stego audio\n",
        "extracted_message = framework_test.extract_message(output_path, len(message))\n",
        "print(f\"\\nOriginal Message: {message}\")\n",
        "print(f\"Extracted Message from new audio: {extracted_message}\")"
      ],
      "metadata": {
        "id": "eH9P_-wMHSiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "37119d74-0354-4d7d-f767-e7353bec70cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-3352637121.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  self.audio, self.sr = librosa.load(audio_path, sr=sr, mono=True)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/steganography/input.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/drive/MyDrive/Colab Notebooks/steganography/input.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-3555589196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test.wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mframework_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitialize_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-3076333152.py\u001b[0m in \u001b[0;36mInitialize_components\u001b[0;34m(self, audio_path, method)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mInitialize_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sign-encoding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"\"\"Initialize components\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_magnitudes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_non_critical_coeffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_magnitudes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-3352637121.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, audio_path, audio_data, frame_size, hop_length, sr)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maudio_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-122>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/steganography/input.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Initialize the steganography system\n",
        "stego = SpreadSpectrum(carrier_freq=10000, chip_rate=100, snr=20)\n",
        "\n",
        "# Embed a message\n",
        "secret_message = \"Hello, this is a secret!\"\n",
        "host_audio = \"drive/MyDrive/Colab Notebooks/steganography/input.wav\"\n",
        "stego_audio = \"stego_audio.wav\"\n",
        "\n",
        "print(f\"Embedding message: {secret_message}\")\n",
        "stego.embed(host_audio, secret_message, stego_audio)\n",
        "\n",
        "# Extract the message\n",
        "extracted_message = stego.extract(stego_audio, len(secret_message))\n",
        "print(f\"Extracted message: {extracted_message}\")"
      ],
      "metadata": {
        "id": "S-CAyxXjMkfj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}