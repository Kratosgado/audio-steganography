{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kratosgado/audio-steganography/blob/staging/steg-ai/core_modules/Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub.config import get_kaggle_credentials"
      ],
      "metadata": {
        "id": "WAOLoGfxXZbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c9aca8-8669-44b6-fec6-2e5e4de1e9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kagglehub.login(get_kaggle_credentials())"
      ],
      "metadata": {
        "id": "hV_XF4Z2APKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "cb055ba8508d44d3838b2ddbe379b585",
            "d935e22d64ee44c7844cbe85de09676b",
            "a4c91c2049b040358dd65201db33a67e",
            "d2a2328006734257934ba1885cc382c5",
            "44bceaeed03e49dd89bdea25894872a8",
            "253a2ca42a0945a694e1085071e038b9",
            "56250b93e8a84f4395db018c19817297",
            "a25672cca492417e87f503074fab7377",
            "06049b0cbf6b470da7f9ff3257afd96d",
            "1f703bbf0330406a9217e281736c95e0",
            "f0ac0e72d8d642c887b38c262e80d6d5",
            "a668c9be13c547a1825af9ea3fb1a8ed",
            "34d5ede13a584c858f0e525743884101",
            "e06b0b41115847fd8514ee2e4b2121e0",
            "825e578844224fae84b9310e8471b938",
            "ccc6cac27ce54f5b848940ebf3e66cc5",
            "9f961788d2f747c5b015e00d0b808fc7",
            "4aa32faea90741138938f70dbd9ff785",
            "92320fc983f04a80ae025a0ee4fdb494",
            "1ba5add594004752ad534d5e69e315f1"
          ]
        },
        "outputId": "78723828-8d38-4876-8f5b-ac3cc22d2689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggleâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb055ba8508d44d3838b2ddbe379b585"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QXp8Vn1BAu2P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3 shimmy torchvggish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iZE9vuGCIj4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d415ba-91ee-4394-96d7-838e6129e54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "from scipy.fft import dct, idct\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.distributions import Normal\n",
        "import torch.nn.functional as F\n",
        "import gymnasium as gym\n",
        "import random\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J5uq1C49Mc3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2444f1c-65fc-4e8c-c26f-073b8d7b4561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNC_gfrXNLFw"
      },
      "source": [
        "# --- UTILITY FUNCTIONS ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_55FxjzNNKHD"
      },
      "outputs": [],
      "source": [
        "NORM_NUM = 32768\n",
        "def string_to_bits(message):\n",
        "  \"\"\"Convert a string to a sequence of bits.\"\"\"\n",
        "  return np.array([int(bit) for bit in ''.join(format(ord(char), '08b') for char in message)], dtype=np.float32)\n",
        "\n",
        "def bits_to_string(bits):\n",
        "  \"\"\"Convert a sequence of bits to a string.\"\"\"\n",
        "  text = ''\n",
        "  for bit in range(0, len(bits), 8):\n",
        "    if bit + 8 <= len(bits):\n",
        "      byte = ''.join(str(bit) for bit in bits[bit:bit + 8])\n",
        "      text += chr(int(byte, 2))\n",
        "  return text\n",
        "\n",
        "class CustomLoggingCallback(BaseCallback):\n",
        "  \"\"\" A custom callback that logs additional information from the environment. \"\"\"\n",
        "  def __init__(self, verbose=0):\n",
        "    super(CustomLoggingCallback, self).__init__(verbose)\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    \"\"\"This method is called after each step in the environment.   \"\"\"\n",
        "    # Accessing environment infos from the VecEnv wrapper\n",
        "    if self.locals.get('infos'):\n",
        "      for info in self.locals['infos']:\n",
        "        # Ensure info is a dictionary and contains the required keys\n",
        "        if isinstance(info, dict):\n",
        "          self.logger.record('rollout/ep_snr', info['snr'])\n",
        "          self.logger.record('rollout/ep_reward', info['reward'])\n",
        "          # self.logger.record('rollout/ep_snr', info['psnr'])\n",
        "          self.logger.record('rollout/ep_ber', info['ber'])\n",
        "          self.logger.record('rollout/ep_extraction_accuracy', info['extraction_accuracy'])\n",
        "          # self.logger.record('rollout/ep_detection_prob', info['detection_prob'])\n",
        "          self.logger.record('rollout/ep_action', info['action'])\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV_OdAlXNoLW"
      },
      "source": [
        "# --- HYPERPARAMETERS ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SLavUsivNtBI"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  \"\"\"Class to hold all hyperparameters.\"\"\"\n",
        "  #Audio processing\n",
        "  FRAME_SIZE = 1024 #2048\n",
        "  HOP_LENGTH = 256 #512\n",
        "  NON_CRITICAL_PERCENT = 0.1 # Modify bottom 10% of coeffs by magnitude\n",
        "  STATE_DIM = 1024\n",
        "  SAMPLE_RATE = 22050\n",
        "  N_MELS = 128\n",
        "\n",
        "  # RL Training\n",
        "  EPISODES = 80000\n",
        "  # EPISODES = 100000\n",
        "  LEARNING_RATE_ACTOR = 3e-4\n",
        "  LEARNING_RATE_CRITIC = 3e-4\n",
        "  GAMMA = 0.99 # Discount factor\n",
        "  GAE_LAMBDA = 0.95 # Lambda for Generalized Advantage Estimation\n",
        "  PPO_EPSILON = 0.2 # Epsilon for clipping in PPO\n",
        "  PPO_EPOCHS = 10 # Number of epochs for PPO update\n",
        "  N_STEPS = 1024\n",
        "  CLIP_RANGE=0.2\n",
        "  ENT_COEF=0.01\n",
        "  BATCH_SIZE = 64\n",
        "  LEARNING_RATE = 3e-4\n",
        "\n",
        "  # Environment Network Pre-training\n",
        "  PRETRAIN_EPOCHS = 10\n",
        "  PRE_TRAIN_LR = 1e-3\n",
        "  PRE_TRAIN_BATCH_SIZE = 32\n",
        "\n",
        "  # Reward weights\n",
        "  SNR_WEIGHTS = 0.4 # Weight for SNR in reward. Tuned to be on a similar scale to detection prob.\n",
        "  # DETECTION_WEIGHT = 1.0 # Weight for detection probability in reward.\n",
        "  # IMPERCEPTIBILITY_WEIGHT = 0.3\n",
        "  # UNDETECTABILITY_WEIGHT = 0.3\n",
        "  EXTRACTION_ACCURACY_WEIGHT = 0.6\n",
        "\n",
        "  # spread spectrum parameters\n",
        "  CARRIER_FREQ_SIZE = 16\n",
        "  CHIP_RATE_SIZE = 8\n",
        "  SNR_DB_SIZE = 8\n",
        "  MSG_SIZE = 16\n",
        "  TOTAL_PARAM_SIZE = CARRIER_FREQ_SIZE + CHIP_RATE_SIZE + SNR_DB_SIZE + MSG_SIZE\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-feRKGXJB5t"
      },
      "source": [
        "# --- MODULE 1: AUDIO PREPROCESSOR ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z-rBWB4UJAyM"
      },
      "outputs": [],
      "source": [
        "class AudioPreprocessor:\n",
        "    \"\"\"Handles audio loading, MDCT, and inverse MDCT with sign preservation.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_audio(path):\n",
        "        \"\"\"Load WAV audio file and resample to cfg.SAMPLE_RATE\"\"\"\n",
        "        audio, _ = librosa.load(path, sr=cfg.SAMPLE_RATE)\n",
        "        return AudioPreprocessor.normalize_audio(audio)\n",
        "\n",
        "    @staticmethod\n",
        "    def resample_audio(waveform, sr) -> np.ndarray:\n",
        "        \"\"\"Resample audio to cfg.SAMPLE_RATE\"\"\"\n",
        "        audio = librosa.resample(waveform, orig_sr=sr, target_sr=cfg.SAMPLE_RATE)\n",
        "        return AudioPreprocessor.normalize_audio(audio)\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_audio(waveform) -> np.ndarray:\n",
        "        \"\"\"Normalize audio to [-1, 1]\"\"\"\n",
        "        return waveform / np.max(np.abs(waveform))\n",
        "\n",
        "    @staticmethod\n",
        "    def stft(waveform: np.ndarray):\n",
        "        \"\"\"Compute Short-Time Fourier Transform (STFT)\"\"\"\n",
        "        return librosa.stft(waveform, n_fft=cfg.FRAME_SIZE, hop_length=cfg.HOP_LENGTH)\n",
        "\n",
        "    @staticmethod\n",
        "    def istft(stft_matrix, length):\n",
        "        \"\"\"Compute Inverse Short-Time Fourier Transform (ISTFT)\"\"\"\n",
        "        return librosa.istft(stft_matrix, hop_length=cfg.HOP_LENGTH, n_fft=cfg.FRAME_SIZE, length=length)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_mdct(waveform):\n",
        "        \"\"\"\n",
        "        Compute Modified Discrete Cosine Transform (MDCT) using STFT and DCT.\n",
        "        Returns both magnitudes and phases to preserve sign information.\n",
        "        \"\"\"\n",
        "        stft = AudioPreprocessor.stft(waveform)\n",
        "        magnitudes = np.abs(stft)\n",
        "        phases = np.angle(stft)\n",
        "        return magnitudes, phases\n",
        "\n",
        "    @staticmethod\n",
        "    def get_non_critical_coeffs(mdct_coeffs, percentile=10):\n",
        "        \"\"\"Identify non-critical coefficients (lowest magnitude)\"\"\"\n",
        "        magnitudes = np.abs(mdct_coeffs)\n",
        "        threshold = np.percentile(magnitudes.flatten(), percentile)\n",
        "        return magnitudes < threshold\n",
        "\n",
        "    @staticmethod\n",
        "    def reconstruct_audio(magnitudes, phases, length):\n",
        "        \"\"\"\n",
        "        Reconstruct audio from magnitude and phase.\n",
        "        The phase information preserves the signs even if magnitudes are modified.\n",
        "        \"\"\"\n",
        "        # Reconstruct complex STFT\n",
        "        stft = magnitudes * np.exp(1j * phases)\n",
        "\n",
        "        # Inverse STFT to get audio\n",
        "        reconstructed_audio = AudioPreprocessor.istft(stft, length)\n",
        "        return reconstructed_audio\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_spectrogram(waveform, sr, title):\n",
        "        \"\"\"Visualize audio spectrogram\"\"\"\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        S = librosa.amplitude_to_db(np.abs(librosa.stft(waveform)), ref=np.max)\n",
        "        librosa.display.specshow(S, sr=sr, x_axis='time', y_axis='log')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title(title)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_mdct_coefficients(mdct_coeffs, title=\"MDCT Coefficients\"):\n",
        "        \"\"\"Visualize MDCT coefficients\"\"\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(np.abs(mdct_coeffs), aspect='auto', origin='lower')\n",
        "        plt.colorbar()\n",
        "        plt.title(f\"{title} - Magnitudes\")\n",
        "        plt.xlabel(\"Time Frame\")\n",
        "        plt.ylabel(\"Frequency Bin\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(np.sign(mdct_coeffs), aspect='auto', origin='lower', cmap='RdBu')\n",
        "        plt.colorbar()\n",
        "        plt.title(f\"{title} - Signs\")\n",
        "        plt.xlabel(\"Time Frame\")\n",
        "        plt.ylabel(\"Frequency Bin\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def save_audio(audio: np.ndarray, sr: int, path: str):\n",
        "        \"\"\"Save audio to file\"\"\"\n",
        "        sf.write(path, audio, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyIIZSInKMwW"
      },
      "source": [
        "# --- MODULE 2: EMBEDDING/EXTRACTION MODULE ---\n",
        "Main Sign encoding class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bc5xRFmqKK_m"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class EmbeddingModule(ABC):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def embed(self, *args, **kwargs) -> np.ndarray:\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def extract(self, *args, **kwargs) -> list[int]:\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def set_parameters(self, action):\n",
        "    pass\n",
        "\n",
        "class SignEncoding(EmbeddingModule):\n",
        "  \"\"\"Embeds and extracts messages from MDCT coefficients.\"\"\"\n",
        "\n",
        "  def set_parameters(self, action):\n",
        "    return action[0]\n",
        "\n",
        "  def embed(self, waveform, action, msg_bits: np.ndarray, **kwargs):\n",
        "    \"\"\"Embed message using sign encoding in non-critical coefficients\"\"\"\n",
        "    magnitudes, phases = AudioPreprocessor.compute_mdct(waveform)\n",
        "    self.mask = AudioPreprocessor.get_non_critical_coeffs(magnitudes)\n",
        "    alpha = action\n",
        "    # Apply mask to get non-critical coefficients\n",
        "    coeffs = magnitudes.copy()\n",
        "    non_critical = coeffs[self.mask]\n",
        "\n",
        "    # Ensure we have enough coefficients for the message\n",
        "    if len(non_critical) < len(msg_bits):\n",
        "        raise ValueError(\"Message too long for available non-critical coefficients\")\n",
        "\n",
        "    # Embed message using sign encoding\n",
        "    for i, bit in enumerate(msg_bits):\n",
        "        sign = 1 if bit == 1 else -1\n",
        "        non_critical[i] = sign * np.abs(non_critical[i]) * (1 + alpha)\n",
        "\n",
        "    # Update coefficients\n",
        "    coeffs[self.mask] = non_critical\n",
        "    self.magnitudes = coeffs\n",
        "\n",
        "\n",
        "    return AudioPreprocessor.reconstruct_audio(coeffs, phases, len(waveform))\n",
        "\n",
        "  def extract(self, stego_waveform, bits_len, **kwargs):\n",
        "    \"\"\"Extract message from non-critical coefficients\"\"\"\n",
        "    # Apply mask to get non-critical coefficients\n",
        "    # magnitudes, _ = AudioPreprocessor.compute_mdct(stego_waveform)\n",
        "    non_critical = self.magnitudes[self.mask]\n",
        "\n",
        "    # Extract message from sign\n",
        "    msg_bits = []\n",
        "    for i in range(bits_len):\n",
        "        sign = 1 if non_critical[i] >= 0 else -1\n",
        "        bit = 1 if sign > 0 else 0\n",
        "        msg_bits.append(bit)\n",
        "\n",
        "    # Convert binary to string\n",
        "    return msg_bits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmFr72llR9ks"
      },
      "source": [
        "### Spread Spectrum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Iv0zqtkMSArs"
      },
      "outputs": [],
      "source": [
        "class SpreadSpectrum(EmbeddingModule):\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Spread Spectrum steganography system\"\"\"\n",
        "        # Parameters for Gold sequence generation (example values)\n",
        "        self.taps1 = [5, 2]\n",
        "        self.taps2 = [5, 4, 2, 1]  # Must be a preferred pair with taps1\n",
        "        self.seed1 = 0b11111\n",
        "        self.seed2 = 0b10101\n",
        "\n",
        "        self.action_ranges = {\n",
        "            \"carrier_freq\": (5000, 15000),\n",
        "            \"chip_rate\": (3, 200),\n",
        "            \"snr\": (20, 150),\n",
        "        }\n",
        "\n",
        "    def _scale_action(self, normalized_val, low, high):\n",
        "        \"\"\"Scale from [-1, 1] to [low, high]\"\"\"\n",
        "        return int(low + (normalized_val) * (high - low))\n",
        "\n",
        "    def set_parameters(self, action):\n",
        "        \"\"\"\n",
        "        Parameters(action):\n",
        "          carrier_freq (int): Carrier frequency in Hz for embedding\n",
        "          chip_rate (int): How many samples per bit (spreading factor)\n",
        "          snr (int): Desired Signal to noise ratio in dB for embedding\n",
        "        \"\"\"\n",
        "        # Scale normalized actions to original ranges\n",
        "        carrier_freq = self._scale_action(\n",
        "            action[0], *self.action_ranges[\"carrier_freq\"]\n",
        "        )\n",
        "        chip_rate = self._scale_action(action[1], *self.action_ranges[\"chip_rate\"])\n",
        "        snr_db = self._scale_action(action[2], *self.action_ranges[\"snr\"])\n",
        "        return [carrier_freq, chip_rate, snr_db]\n",
        "\n",
        "    def _generate_m_sequence(self, taps, length, initial_state):\n",
        "        \"\"\"Generate an m-sequence.\"\"\"\n",
        "        lfsr = initial_state\n",
        "        seq = np.zeros(length)\n",
        "        # mask = sum(1 << (t - 1) for t in taps) # Mask is not used in this implementation\n",
        "\n",
        "        for i in range(length):\n",
        "            seq[i] = 1 if (lfsr & 1) else -1  # Convert to bipolar (-1, 1)\n",
        "            feedback = 0\n",
        "            for tap in taps:\n",
        "                feedback ^= (lfsr >> (tap - 1)) & 1\n",
        "            # Adjust the shift based on the number of bits in the initial state\n",
        "            lfsr = (lfsr >> 1) | (\n",
        "                feedback << (len(bin(initial_state)) - 3)\n",
        "            )  # Assuming initial_state is not 0\n",
        "\n",
        "        return seq\n",
        "\n",
        "    def _generate_spreading_code(self, length):\n",
        "        \"\"\"Generate a Gold sequence.\"\"\"\n",
        "        # The lengths of the m-sequences must be the same\n",
        "        # and derived from the same primitive polynomial.\n",
        "        # The taps define the primitive polynomials.\n",
        "        # The seeds are the initial states of the LFSRs.\n",
        "\n",
        "        m_seq1 = self._generate_m_sequence(self.taps1, length, self.seed1)\n",
        "        m_seq2 = self._generate_m_sequence(self.taps2, length, self.seed2)\n",
        "\n",
        "        # XOR the two m-sequences\n",
        "        gold_seq = m_seq1 * m_seq2  # For bipolar sequences, XOR is multiplication\n",
        "\n",
        "        return gold_seq\n",
        "\n",
        "    def _int_to_bits(self, decimal_value, num_bits):\n",
        "        \"\"\"Convert a decimal value to a binary string of a fixed number of bits.\"\"\"\n",
        "        binary_string = bin(decimal_value)[2:].zfill(num_bits)\n",
        "        return [int(bit) for bit in binary_string]\n",
        "\n",
        "    def _bits_to_int(self, binary_string):\n",
        "        \"\"\"Convert a binary string to a decimal value.\"\"\"\n",
        "        return int(binary_string, 2)\n",
        "\n",
        "    def _embed_bits_lsb(self, audio, bits_to_embed, start_sample=0):\n",
        "        \"\"\"Embed a sequence of bits into the least significant bits of audio samples.\"\"\"\n",
        "        audio_int = (audio * NORM_NUM).astype(np.int16)\n",
        "\n",
        "        if len(bits_to_embed) > len(audio_int):\n",
        "            raise ValueError(\"Not enough audio samples to embed all bits.\")\n",
        "\n",
        "        # Create a copy to modify\n",
        "        audio_int_modified = audio_int.copy()\n",
        "\n",
        "        # Embed the bits starting from start_sample\n",
        "        for i, bit in enumerate(bits_to_embed):\n",
        "            if start_sample + i < len(audio_int_modified):\n",
        "                # Replace the LSB of each 16-bit sample\n",
        "                sample_index = start_sample + i\n",
        "                # Clear the LSB and set it to the new bit\n",
        "                audio_int_modified[sample_index] = (\n",
        "                    audio_int_modified[sample_index] & 0xFE\n",
        "                ) | bit\n",
        "\n",
        "        return audio_int_modified.astype(np.float32) / NORM_NUM\n",
        "\n",
        "    def _extract_bits_lsb(self, audio, num_bits_to_extract, start_sample=0):\n",
        "        \"\"\"Extract a sequence of bits from the least significant bits of audio samples.\"\"\"\n",
        "        audio_int = (audio * NORM_NUM).astype(np.int16)\n",
        "\n",
        "        if num_bits_to_extract + start_sample > len(audio_int):\n",
        "            raise ValueError(\"Cannot extract more bits than available LSBs.\")\n",
        "\n",
        "        extracted_bits = []\n",
        "        for i in range(num_bits_to_extract):\n",
        "            sample_index = start_sample + i\n",
        "            # Extract the LSB\n",
        "            bit = audio_int[sample_index] & 1\n",
        "            extracted_bits.append(bit)\n",
        "\n",
        "        return extracted_bits\n",
        "\n",
        "    def embed(self, waveform, msg_bits: np.ndarray, action, **kwargs):\n",
        "        \"\"\"\n",
        "        Embed a message into an audio file using spread spectrum with LSB hiding of parameters.\n",
        "\n",
        "        Parameters:\n",
        "          waveform (ndarray): Original audio data\n",
        "          msg_bits (ndarray): Message bits to embed\n",
        "          action (tuple): Parameters for embedding (carrier_freq, chip_rate, snr_db)\n",
        "        \"\"\"\n",
        "        # Set parameters from action\n",
        "        carrier_freq, chip_rate, snr_db = action\n",
        "\n",
        "        # print(f\"Embedding parameters: carrier_freq={carrier_freq}, chip_rate={chip_rate}, snr_db={snr_db}, message_length={message_length}\")\n",
        "\n",
        "        msg_bits_bipolar = msg_bits * 2 - 1 # Convert message bits to bipolar (-1, 1)\n",
        "\n",
        "        # Generate spreading codes\n",
        "        code_length = len(msg_bits_bipolar) * chip_rate\n",
        "        spreading_code = self._generate_spreading_code(code_length)\n",
        "\n",
        "        # Create the spread message signal\n",
        "        spread_message = np.repeat(msg_bits_bipolar, chip_rate) * spreading_code\n",
        "\n",
        "        # Create carrier signal (sine wave at carrier frequency)\n",
        "        t = np.arange(len(spread_message)) / cfg.SAMPLE_RATE\n",
        "        carrier = np.sin(2 * np.pi * carrier_freq * t)\n",
        "\n",
        "        modulated = spread_message * carrier  # Modulate the message onto the carrier\n",
        "\n",
        "        # Adjust the signal power based on desired SNR\n",
        "        signal_power = np.var(waveform)\n",
        "        message_power = np.var(modulated)\n",
        "        # Add a small epsilon to avoid division by zero if message_power is 0\n",
        "        epsilon = 1e-8\n",
        "        desired_message_power = signal_power / (10 ** (snr_db / 10))\n",
        "        scaling_factor = np.sqrt(desired_message_power / (message_power + epsilon))\n",
        "        modulated = modulated * scaling_factor\n",
        "\n",
        "        stego_waveform = waveform.copy()\n",
        "        # Pad or truncate the modulated signal to match audio length\n",
        "        if len(modulated) < len(stego_waveform):\n",
        "            modulated = np.pad(\n",
        "                modulated, (0, len(stego_waveform) - len(modulated)), \"constant\"\n",
        "            )\n",
        "        else:\n",
        "            modulated = modulated[: len(stego_waveform)]\n",
        "\n",
        "        # Add the modulated signal to the audio (starting after parameter bits)\n",
        "        stego_waveform = stego_waveform + modulated\n",
        "\n",
        "        # Calculate message length in bits\n",
        "        message_length = len(msg_bits)\n",
        "\n",
        "        # Convert parameters to binary strings for LSB embedding\n",
        "        carrier_freq_bits = self._int_to_bits(carrier_freq, 16)\n",
        "        chip_rate_bits = self._int_to_bits(chip_rate, 8)\n",
        "        snr_db_bits = self._int_to_bits(snr_db, 8)\n",
        "        message_length_bits = self._int_to_bits(message_length, 16)\n",
        "\n",
        "        # Concatenate all parameter bits\n",
        "        param_bits = (\n",
        "            carrier_freq_bits + chip_rate_bits + snr_db_bits + message_length_bits\n",
        "        )\n",
        "        stego_waveform = self._embed_bits_lsb(\n",
        "            stego_waveform, param_bits, start_sample=0\n",
        "        )\n",
        "\n",
        "        return stego_waveform\n",
        "\n",
        "    def extract_param_bits(self, bits, start=None, end=None) -> int:\n",
        "        \"\"\"Extract parameter bits from a list of bits.\"\"\"\n",
        "        if start is None:\n",
        "            extracted = bits[:end]\n",
        "        if end is None:\n",
        "            extracted = bits[start:]\n",
        "        extracted = bits[start:end]\n",
        "        to_str = \"\".join(str(bit) for bit in extracted)\n",
        "        return self._bits_to_int(to_str)\n",
        "\n",
        "    def extract(self, stego_waveform, original_audio_path=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Extract a hidden message from a stego audio file.\n",
        "\n",
        "        Parameters:\n",
        "            stego_waveform (ndarray): Stego audio data\n",
        "            message_length (int): Optional length of the hidden message in bits\n",
        "            original_audio_path (str): Optional path to original audio for comparison\n",
        "        \"\"\"\n",
        "        extracted_param_bits = self._extract_bits_lsb(\n",
        "            stego_waveform, cfg.TOTAL_PARAM_SIZE, start_sample=0\n",
        "        )\n",
        "\n",
        "        start, end = 0, cfg.CARRIER_FREQ_SIZE\n",
        "        carrier_freq = self.extract_param_bits(extracted_param_bits, start, end)\n",
        "        start, end = cfg.CARRIER_FREQ_SIZE, cfg.CARRIER_FREQ_SIZE + cfg.CHIP_RATE_SIZE\n",
        "        chip_rate = self.extract_param_bits(extracted_param_bits, start, end)\n",
        "        start, end = (\n",
        "            cfg.CARRIER_FREQ_SIZE + cfg.CHIP_RATE_SIZE,\n",
        "            cfg.CARRIER_FREQ_SIZE + cfg.CHIP_RATE_SIZE + cfg.SNR_DB_SIZE,\n",
        "        )\n",
        "        snr_db = self.extract_param_bits(extracted_param_bits, start, end)\n",
        "        start, end = cfg.CARRIER_FREQ_SIZE + cfg.CHIP_RATE_SIZE + cfg.SNR_DB_SIZE, None\n",
        "        message_length = self.extract_param_bits(extracted_param_bits, start, end)\n",
        "\n",
        "        # print(f\"Extracted parameters: carrier_freq={carrier_freq}, chip_rate={chip_rate}, snr_db={snr_db}, message_length={message_length}\")\n",
        "\n",
        "        # If original audio is provided, subtract it to get just the message\n",
        "        # if original_audio_path:\n",
        "        #     y_original, _ = librosa.load(original_audio_path, sr=cfg.SAMPLE_RATE)\n",
        "        #     # Ensure lengths match before subtraction\n",
        "        #     min_len = min(len(stego_waveform), len(y_original))\n",
        "        #     y_diff = stego_waveform[:min_len] - y_original[:min_len]\n",
        "        # else:\n",
        "        y_diff = stego_waveform\n",
        "\n",
        "        # Generate the same spreading code used in embedding\n",
        "        code_length = message_length * chip_rate\n",
        "        spreading_code = self._generate_spreading_code(code_length)\n",
        "\n",
        "        # Create carrier signal\n",
        "        t = np.arange(len(spreading_code)) / cfg.SAMPLE_RATE\n",
        "        carrier = np.sin(2 * np.pi * carrier_freq * t)\n",
        "\n",
        "        # Pad or truncate the carrier to match the difference signal\n",
        "        if len(carrier) < len(y_diff):\n",
        "            carrier = np.pad(carrier, (0, len(y_diff) - len(carrier)), \"constant\")\n",
        "        else:\n",
        "            carrier = carrier[: len(y_diff)]\n",
        "\n",
        "        # Demodulate the signal\n",
        "        demodulated = y_diff * carrier\n",
        "\n",
        "        # Correlate with spreading code to extract bits\n",
        "        extracted_bits = []\n",
        "        for i in range(message_length):\n",
        "            start = i * chip_rate\n",
        "            end = start + chip_rate\n",
        "            if end > len(demodulated):\n",
        "                break\n",
        "            segment = demodulated[start:end]\n",
        "            code_segment = spreading_code[start:end]\n",
        "\n",
        "            # Calculate correlation\n",
        "            correlation = np.sum(segment * code_segment)\n",
        "            extracted_bits.append(1 if correlation > 0 else 0)\n",
        "\n",
        "        return extracted_bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfre1MB1Julg"
      },
      "source": [
        "# --- MODULE 3: RL ACTOR-CRITIC NETWORKS ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UmJ4bvTvJeK2"
      },
      "outputs": [],
      "source": [
        "class TransferPolicyNetwork(nn.Module):\n",
        "  def __init__(self, pretrained_feature_extractor):\n",
        "    super().__init__()\n",
        "    self.feature_extractor = pretrained_feature_extractor\n",
        "    for param in self.feature_extractor.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.policy_head = nn.Sequential(\n",
        "        nn.Linear(self.feature_extractor.combiner.out_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, observations):\n",
        "    features = self.feature_extractor(observations)\n",
        "    return self.policy_head(features)\n",
        "\n",
        "# Example usage with VGGish (audio feature extractor)\n",
        "# vggish = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
        "# policy_net = TransferPolicyNetwork(vggish).to(device)\n",
        "\n",
        "# 7. Feature Extractor for PPO\n",
        "class AudioFeatureExtractor(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space: spaces.Dict):\n",
        "        super().__init__(observation_space, features_dim=256)\n",
        "\n",
        "        # Feature-specific processing\n",
        "        self.mfcc_net = nn.Sequential(\n",
        "            nn.Linear(observation_space['mfcc'].shape[0], 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.sc_net = nn.Linear(1, 32)\n",
        "        self.rms_net = nn.Linear(1, 32)\n",
        "        self.zcr_net = nn.Linear(1, 32)\n",
        "        self.msg_net = nn.Linear(1, 32)\n",
        "\n",
        "        # Combined processing\n",
        "        self.combined = nn.Sequential(\n",
        "            nn.Linear(128+32*4, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, observations: dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        mfcc = self.mfcc_net(observations[\"mfcc\"])\n",
        "        sc = self.sc_net(observations[\"spectral_centroid\"])\n",
        "        rms = self.rms_net(observations[\"rms\"])\n",
        "        zcr = self.zcr_net(observations[\"zcr\"])\n",
        "        msg = self.msg_net(observations[\"bits_len\"])\n",
        "\n",
        "        combined = torch.cat([mfcc, sc, rms, zcr, msg], dim=1)\n",
        "        return self.combined(combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH5KOS4wJw0g"
      },
      "source": [
        "# --- MODULE 4: ENVIRONMENT NETWORK (STEGANALYZER) ---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Steganalysis"
      ],
      "metadata": {
        "id": "tSLvRZNIzkAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a random message (for the RL environment)\n",
        "def generate_random_message(length=50):\n",
        "    \"\"\"Generates a random string message.\"\"\"\n",
        "    import string\n",
        "    letters = string.ascii_letters + string.digits + string.punctuation + \" \"\n",
        "    return ''.join(random.choice(letters) for i in range(length))\n",
        "\n",
        "def extract_audio_features(waveform, bits_len):\n",
        "    features = {}\n",
        "    features['mfcc'] = librosa.feature.mfcc(\n",
        "        y=waveform, sr=cfg.SAMPLE_RATE,\n",
        "        n_mfcc=cfg.N_MELS,\n",
        "        n_fft=cfg.FRAME_SIZE, hop_length=cfg.HOP_LENGTH\n",
        "    ).mean(axis=1)\n",
        "\n",
        "    features['spectral_centroid'] = librosa.feature.spectral_centroid(\n",
        "        y=waveform, sr=cfg.SAMPLE_RATE\n",
        "    ).mean(keepdims=True)\n",
        "\n",
        "    features['rms'] = librosa.feature.rms(y=waveform).mean(keepdims=True)\n",
        "    features['zcr'] = librosa.feature.zero_crossing_rate(y=waveform).mean(keepdims=True)\n",
        "    features[\"bits_len\"] = bits_len/1000\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "fZuDBaKGXaM5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransferSteganalysis(nn.Module):\n",
        "  def __init__(self, pretrained_cnn):\n",
        "    super().__init__()\n",
        "    self.features = pretrained_cnn.features[:8] # first 8 layers\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool1d(output_size=1),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    return self.classifier(x)\n",
        "\n",
        "# Example with pre-trained audio CNN\n",
        "# pretrained = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
        "# steganalysis_net = TransferSteganalysis(pretrained).to(device)"
      ],
      "metadata": {
        "id": "OwRDsnqdznwT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Environment"
      ],
      "metadata": {
        "id": "TSOQmgvV0XoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vk-lzxwRJt0P"
      },
      "outputs": [],
      "source": [
        " #5. Custom Gym Environment for RL Training\n",
        "class AudioStegoEnv(gym.Env):\n",
        "  def __init__(self, dataset, method=\"sign-encoding\"):\n",
        "    super(AudioStegoEnv, self).__init__()\n",
        "    self.dataset = dataset\n",
        "\n",
        "    self.action_space = spaces.Box(low=0.0, high=0.1, shape=(1,), dtype=np.float32)\n",
        "    if method == \"spread-spectrum\":\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32)\n",
        "\n",
        "    # Define observation space as a dictionary for MultiInputPolicy\n",
        "    mfcc_dim = cfg.N_MELS\n",
        "    spectral_centroid_dim = 1 # mean over frames\n",
        "    rms_dim = 1 # mean over frames\n",
        "    zcr_dim = 1 # mean over frames\n",
        "    msg_dim = 1\n",
        "\n",
        "    self.observation_space = spaces.Dict({\n",
        "            \"mfcc\": spaces.Box(low=-np.inf, high=np.inf, shape=(cfg.N_MELS,)),\n",
        "            \"spectral_centroid\": spaces.Box(low=0, high=np.inf, shape=(1,)),\n",
        "            \"rms\": spaces.Box(low=0, high=np.inf, shape=(1,)),\n",
        "            \"zcr\": spaces.Box(low=0, high=np.inf, shape=(1,)),\n",
        "            \"bits_len\": spaces.Box(low=0, high=np.inf, shape=(1,)),\n",
        "        })\n",
        "\n",
        "    self.embedder: EmbeddingModule = SignEncoding() if method == \"sign-encoding\" else SpreadSpectrum()\n",
        "\n",
        "    # Initialize state\n",
        "    # self.reset()\n",
        "\n",
        "  def reset_with_audio(self, audio_path, msg):\n",
        "    self.audio_path = audio_path\n",
        "    self.original_waveform = AudioPreprocessor.load_audio(audio_path)\n",
        "    self.msg_bits = string_to_bits(msg)\n",
        "    self.bits_len = len(self.msg_bits)\n",
        "    self.current_waveform = self.original_waveform.copy()\n",
        "    self.current_step = 0\n",
        "    return self._get_obs(), {} # Return observation and info dictionary\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    \"\"\"Reset environment to initial state\"\"\"\n",
        "    super().reset(seed=seed)\n",
        "    msg_len = int(random.random()*100 + 50)\n",
        "    self.msg = generate_random_message(msg_len)\n",
        "    self.msg_bits = string_to_bits(self.msg)\n",
        "    self.bits_len = len(self.msg_bits)\n",
        "    tensor, sr, _ = random.choice(self.dataset)\n",
        "    self.original_waveform = AudioPreprocessor.resample_audio(tensor[0].numpy(), sr=sr)\n",
        "\n",
        "    self.current_waveform = self.original_waveform.copy()\n",
        "    # self.current_step = 0\n",
        "    return self._get_obs(), {} # Return observation and info dictionary\n",
        "\n",
        "  def _get_obs(self):\n",
        "    \"\"\"Extract features and concatenate them as observation\"\"\"\n",
        "    return extract_audio_features(self.current_waveform, self.bits_len)\n",
        "\n",
        "\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Execute one embedding step\"\"\"\n",
        "    action = self.embedder.set_parameters(action)\n",
        "\n",
        "    # Embed message\n",
        "    self.current_waveform = self.embedder.embed(msg_bits = self.msg_bits, waveform=self.original_waveform, action=action)\n",
        "\n",
        "    # Compute rewards\n",
        "    snr = self._calculate_snr()\n",
        "    # psnr = self._calculate_psnr()\n",
        "    # detection_prob = self._simulate_detection()\n",
        "    accuracy, ber = self._calculate_accuracy_ber()\n",
        "    reward = self._calculate_reward(snr,ber, 0, accuracy)\n",
        "\n",
        "    # Update state\n",
        "    # self.current_step += 1\n",
        "    # done = self.current_step >= 10\n",
        "    info = {\n",
        "        \"snr\": snr,\n",
        "        # \"psnr\": psnr,\n",
        "        \"ber\": ber,\n",
        "        # \"detection_prob\": detection_prob,\n",
        "        \"extraction_accuracy\": accuracy,\n",
        "        \"reward\": reward,\n",
        "        \"action\": action\n",
        "    }\n",
        "    return self._get_obs(), reward, True, None, info\n",
        "\n",
        "  def _calculate_snr(self):\n",
        "    \"\"\"Calculate Signal-to-Noise Ratio\"\"\"\n",
        "    # Ensure both audio arrays have the same length before calculating noise\n",
        "    min_len = min(len(self.current_waveform), len(self.original_waveform))\n",
        "    current_audio_trimmed = self.current_waveform[:min_len]\n",
        "    original_audio_trimmed = self.original_waveform[:min_len]\n",
        "\n",
        "    noise = current_audio_trimmed - original_audio_trimmed\n",
        "    signal_power = np.mean(original_audio_trimmed ** 2)\n",
        "    noise_power = np.mean(noise ** 2)\n",
        "\n",
        "    if noise_power == 0:\n",
        "        return 100  # High SNR if no noise\n",
        "\n",
        "    return 10 * np.log10(signal_power / noise_power)\n",
        "\n",
        "  # def _calculate_psnr(self):\n",
        "  #   if len(self.current_waveform) < len(self.original_waveform):\n",
        "  #       stego_waveform_padded = np.pad(self.current_waveform, (0, len(self.original_waveform) - len(self.current_waveform)), 'constant')\n",
        "  #   else:\n",
        "  #       stego_waveform_padded = self.current_waveform[:len(self.original_waveform)]\n",
        "\n",
        "  #   psnr = 10 * np.log10(np.max(self.original_waveform ** 2) / np.mean((self.original_waveform - stego_waveform_padded) ** 2)) if np.mean((self.original_waveform - stego_waveform_padded) ** 2) > 0 else float('inf')\n",
        "  #   return psnr\n",
        "\n",
        "\n",
        "  def _simulate_detection(self):\n",
        "    pass\n",
        "  #   \"\"\"Simulate steganalysis detection\"\"\"\n",
        "  #   # not real\n",
        "  #   snr = self._calculate_snr()\n",
        "  #   return 1 / (1 + np.exp(0.5 * (snr - 50)))  # Logistic function\n",
        "\n",
        "  def _calculate_accuracy_ber(self):\n",
        "    \"\"\"Calculate the accuracy of extracted bits\"\"\"\n",
        "    extracted_bits = self.embedder.extract(stego_waveform =self.current_waveform, bits_len=self.bits_len)\n",
        "    bits_len = len(extracted_bits)\n",
        "\n",
        "    min_len_bits = min(bits_len, self.bits_len)\n",
        "    ber = np.mean([self.msg_bits[i] != extracted_bits[i] for i in range(min_len_bits)]) if min_len_bits > 0 else 1.0 # BER is 1 if no bits to compare\n",
        "    extracted_str = bits_to_string(extracted_bits)\n",
        "    print(f\"Original message: {self.msg}\")\n",
        "    print(f\"Extracted message: {extracted_str}\")\n",
        "    str_len = len(extracted_str)\n",
        "    bits_len = len(self.msg)\n",
        "    min_len_str = min(str_len, bits_len)\n",
        "    str_ber = np.mean([self.msg[i] != extracted_str[i] for i in range(min_len_str)]) if min_len_str > 0 else 1.0 # BER is 1 if no bits to compare\n",
        "\n",
        "    return 1.0 - str_ber, ber\n",
        "\n",
        "  def _calculate_reward(self, snr,ber, detection_prob, extraction_accuracy):\n",
        "    \"\"\"Calculate reward balancing SNR, detectability, and extraction accuracy\"\"\"\n",
        "    # Target: SNR > 50 dB, detection_prob < 0.1, extraction_accuracy close to 1.0\n",
        "    snr_reward = min(snr / 50, 1.0)\n",
        "    # detect_reward = 1.0 - min(detection_prob, 1.0)\n",
        "\n",
        "    # Weighted combination\n",
        "    return (\n",
        "        cfg.SNR_WEIGHTS * snr_reward - ber +\n",
        "        # cfg.DETECTION_WEIGHT * detect_reward +\n",
        "        cfg.EXTRACTION_ACCURACY_WEIGHT * extraction_accuracy\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -- Prepare sample audios --"
      ],
      "metadata": {
        "id": "RKny7R_ZoaM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_dir = \"_assets\"\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
        "  waveform = waveform.numpy()\n",
        "  figure, ax = plt.subplots()\n",
        "  ax.specgram(waveform[0], Fs=sample_rate)\n",
        "  figure.suptitle(title)\n",
        "  figure.tight_layout()\n",
        "\n",
        "dataset = torchaudio.datasets.YESNO(sample_dir, download=True)\n",
        "sample_path = \"_assets/waves_yesno/0_0_0_0_1_1_1_1.wav\""
      ],
      "metadata": {
        "id": "PdIDqIVfWReT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73d4304-3a0d-45d6-8faa-be881848f31d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.49M/4.49M [00:00<00:00, 6.33MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/datasets/utils.py:25: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extract(file_, to_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 8\n",
        "# waveform, sr, label = dataset[i]\n",
        "# processor = AudioPreprocessor()\n",
        "# waveform = AudioPreprocessor.resample_audio(waveform[0].numpy(), sr)\n",
        "# features = extract_audio_features(waveform, 500)\n",
        "# print(waveform.shape)\n",
        "# mod = waveform.copy()[:-98]\n",
        "# mod.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqbrpSgJBole",
        "outputId": "2a87f10c-ffff-4c2c-e473-0df5b67a8bd8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(137592,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137494,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# env = AudioStegoEnv(dataset, method=\"spread-spectrum\")\n",
        "# # env = AudioStegoEnv(dataset, method=\"sign-encoding\")\n",
        "# obs, info = env.reset()\n",
        "# obs, reward, done, truncated, info = env.step([0.5, 0.2, 0])\n",
        "# info"
      ],
      "metadata": {
        "id": "-5K4hSX51J2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69aa1d5b-6647-4aed-8ce4-d866a291aa77"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original message: 2 )m+igg<6>1&J<:{3LME?S$X\\&5]lkPl{M@YuCW}j;\\mogr7<Fo!`TdkS#/Xk,_/#rq^f`wK*!=-\"-'y LD^}Ocm1Z58\n",
            "Extracted message: 2 )m+igg<6>1&J<:{3LME?S$X\\&5]lkPl{M@YuCW}j;\\mogr7<Fo!`TdkS#/Xk\n",
            "]oÂœ{1Ãƒ\u00021Cx?AÃ­=*\r#y LD^}Ocm1Z58\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'snr': np.float32(24.790276),\n",
              " 'ber': np.float64(0.06048387096774194),\n",
              " 'extraction_accuracy': np.float64(0.8064516129032258),\n",
              " 'reward': np.float64(0.6217093035098045),\n",
              " 'action': [10000, 42, 20]}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A69oR2apRBwA"
      },
      "source": [
        "# -- MAIN FRAMEWORK --"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWcvIP6yRIBc"
      },
      "outputs": [],
      "source": [
        "class RLAudioSteganography:\n",
        "  \"\"\"Main framework class\"\"\"\n",
        "  def __init__(self, cfg: Config, method=\"sign-encoding\") -> None:\n",
        "    self.cfg = cfg\n",
        "    self.method = method\n",
        "    self.embedder: EmbeddingModule = SignEncoding() if method == \"sign-encoding\" else SpreadSpectrum()\n",
        "\n",
        "\n",
        "  def Initialize_components(self, audio_path, method=\"sign-encoding\"):\n",
        "    \"\"\"Initialize components\"\"\"\n",
        "    # self.steganalysis_net = SteganalysisCNN()\n",
        "    # self.steganalysis_net = SteganalysisCNN(input_channels=len(self.preprocessor.audio))\n",
        "    # self.steganalysis_net.to(device)\n",
        "\n",
        "  def train_ppo(self, total_timesteps=10000)-> PPO:\n",
        "  # def train_ppo(self, total_timesteps=25000)-> PPO:\n",
        "    \"\"\"Train PPO agent for audio steganography\"\"\"\n",
        "    env = make_vec_env(lambda: AudioStegoEnv(dataset, method=self.method), n_envs=4)\n",
        "\n",
        "    policy_kwargs = dict(\n",
        "        features_extractor_class=AudioFeatureExtractor,\n",
        "        features_extractor_kwargs=dict(),\n",
        "        net_arch=dict(pi=[256, 256], vf=[256, 256])\n",
        "    )\n",
        "    model = PPO(\n",
        "        \"MultiInputPolicy\",\n",
        "        env,\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        verbose=1,\n",
        "        device=device,\n",
        "        learning_rate=cfg.LEARNING_RATE,\n",
        "      )\n",
        "    # Instantiate the custom callback\n",
        "    custom_callback = CustomLoggingCallback()\n",
        "    model.learn(cfg.EPISODES, custom_callback)\n",
        "\n",
        "    return model\n",
        "\n",
        "  def embed_message(self, audio_path, message, output_path, model):\n",
        "    \"\"\"Embed a message into an audio file using trained policy\"\"\"\n",
        "    # Re-initialize preprocessor and compute magnitudes/phases/mask for the specific audio being embedded into\n",
        "    waveform = AudioPreprocessor.load_audio(audio_path)\n",
        "\n",
        "    msg_bits = string_to_bits(message)\n",
        "    env = AudioStegoEnv([],self.method) # Use the correct audio_path and message\n",
        "    obs, info = env.reset_with_audio(audio_path, message)\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    action = self.embedder.set_parameters(action[0])\n",
        "    # Convert message string to bits for embedding\n",
        "    message_bits = string_to_bits(message)\n",
        "    stego_waveform = self.embedder.embed( msg_bits = msg_bits, action = action, waveform=waveform)\n",
        "    AudioPreprocessor.save_audio(stego_waveform,cfg.SAMPLE_RATE, output_path)\n",
        "    print(f\"Stego audio saved to {output_path}\")\n",
        "\n",
        "\n",
        "  def extract_message(self, stego_audio_path, msg_length):\n",
        "    \"\"\"Extract a message from a stego audio file\"\"\"\n",
        "    # Load the stego audio\n",
        "    waveform = AudioPreprocessor.load_audio(stego_audio_path)\n",
        "\n",
        "    extracted_bits = self.embedder.extract(stego_waveform=waveform, message_length= msg_length)\n",
        "    return bits_to_string(extracted_bits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULjz6C-CKiMq"
      },
      "source": [
        "# --- MAIN EXECUTION SCRIPT ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srWhvcBg59Qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e13c3d-ae7c-44e2-a173-85aa421b3954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PPO agent...\n",
            "Using cuda device\n",
            "-----------------------------------------------\n",
            "| rollout/                  |                 |\n",
            "|    ep_action              | [12663, 10, 20] |\n",
            "|    ep_ber                 | 0.00714         |\n",
            "|    ep_extraction_accuracy | 0.986           |\n",
            "|    ep_len_mean            | 1               |\n",
            "|    ep_rew_mean            | 0.311           |\n",
            "|    ep_reward              | 0.857           |\n",
            "|    ep_snr                 | 34.06507        |\n",
            "| time/                     |                 |\n",
            "|    fps                    | 4               |\n",
            "|    iterations             | 1               |\n",
            "|    time_elapsed           | 1976            |\n",
            "|    total_timesteps        | 8192            |\n",
            "-----------------------------------------------\n",
            "-----------------------------------------------\n",
            "| rollout/                  |                 |\n",
            "|    ep_action              | [5000, 10, 140] |\n",
            "|    ep_ber                 | 0.498           |\n",
            "|    ep_extraction_accuracy | 0.0127          |\n",
            "|    ep_len_mean            | 1               |\n",
            "|    ep_rew_mean            | 0.526           |\n",
            "|    ep_reward              | -0.256          |\n",
            "|    ep_snr                 | 29.325487       |\n",
            "| time/                     |                 |\n",
            "|    fps                    | 4               |\n",
            "|    iterations             | 2               |\n",
            "|    time_elapsed           | 3905            |\n",
            "|    total_timesteps        | 16384           |\n",
            "| train/                    |                 |\n",
            "|    approx_kl              | 0.23832294      |\n",
            "|    clip_fraction          | 0.724           |\n",
            "|    clip_range             | 0.2             |\n",
            "|    entropy_loss           | -4.1            |\n",
            "|    explained_variance     | -0.0346         |\n",
            "|    learning_rate          | 0.0003          |\n",
            "|    loss                   | -0.0618         |\n",
            "|    n_updates              | 10              |\n",
            "|    policy_gradient_loss   | -0.158          |\n",
            "|    std                    | 0.931           |\n",
            "|    value_loss             | 0.193           |\n",
            "-----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [5000, 10, 20] |\n",
            "|    ep_ber                 | 0.00528        |\n",
            "|    ep_extraction_accuracy | 0.986          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.578          |\n",
            "|    ep_reward              | 0.806          |\n",
            "|    ep_snr                 | 27.421267      |\n",
            "| time/                     |                |\n",
            "|    fps                    | 4              |\n",
            "|    iterations             | 3              |\n",
            "|    time_elapsed           | 5638           |\n",
            "|    total_timesteps        | 24576          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.09535171     |\n",
            "|    clip_fraction          | 0.606          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -3.84          |\n",
            "|    explained_variance     | 0              |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | -0.0536        |\n",
            "|    n_updates              | 20             |\n",
            "|    policy_gradient_loss   | -0.124         |\n",
            "|    std                    | 0.867          |\n",
            "|    value_loss             | 0.139          |\n",
            "----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [5000, 10, 20] |\n",
            "|    ep_ber                 | 0.00278        |\n",
            "|    ep_extraction_accuracy | 0.989          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.693          |\n",
            "|    ep_reward              | 0.804          |\n",
            "|    ep_snr                 | 26.670792      |\n",
            "| time/                     |                |\n",
            "|    fps                    | 4              |\n",
            "|    iterations             | 4              |\n",
            "|    time_elapsed           | 7009           |\n",
            "|    total_timesteps        | 32768          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.16243647     |\n",
            "|    clip_fraction          | 0.678          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -3.55          |\n",
            "|    explained_variance     | 0              |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | -0.0646        |\n",
            "|    n_updates              | 30             |\n",
            "|    policy_gradient_loss   | -0.119         |\n",
            "|    std                    | 0.788          |\n",
            "|    value_loss             | 0.0921         |\n",
            "----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [6374, 10, 20] |\n",
            "|    ep_ber                 | 0.00595        |\n",
            "|    ep_extraction_accuracy | 0.984          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.763          |\n",
            "|    ep_reward              | 0.858          |\n",
            "|    ep_snr                 | 34.21924       |\n",
            "| time/                     |                |\n",
            "|    fps                    | 4              |\n",
            "|    iterations             | 5              |\n",
            "|    time_elapsed           | 8208           |\n",
            "|    total_timesteps        | 40960          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.07553446     |\n",
            "|    clip_fraction          | 0.551          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -3.27          |\n",
            "|    explained_variance     | 0              |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | -0.0924        |\n",
            "|    n_updates              | 40             |\n",
            "|    policy_gradient_loss   | -0.0997        |\n",
            "|    std                    | 0.735          |\n",
            "|    value_loss             | 0.0579         |\n",
            "----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [5000, 10, 20] |\n",
            "|    ep_ber                 | 0.00139        |\n",
            "|    ep_extraction_accuracy | 0.989          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.781          |\n",
            "|    ep_reward              | 0.816          |\n",
            "|    ep_snr                 | 27.962692      |\n",
            "| time/                     |                |\n",
            "|    fps                    | 5              |\n",
            "|    iterations             | 6              |\n",
            "|    time_elapsed           | 9314           |\n",
            "|    total_timesteps        | 49152          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.038517475    |\n",
            "|    clip_fraction          | 0.403          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -3.06          |\n",
            "|    explained_variance     | 1.19e-07       |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | -0.073         |\n",
            "|    n_updates              | 50             |\n",
            "|    policy_gradient_loss   | -0.075         |\n",
            "|    std                    | 0.697          |\n",
            "|    value_loss             | 0.0381         |\n",
            "----------------------------------------------\n",
            "-----------------------------------------------\n",
            "| rollout/                  |                 |\n",
            "|    ep_action              | [15000, 10, 20] |\n",
            "|    ep_ber                 | 0.00284         |\n",
            "|    ep_extraction_accuracy | 0.989           |\n",
            "|    ep_len_mean            | 1               |\n",
            "|    ep_rew_mean            | 0.769           |\n",
            "|    ep_reward              | 0.82            |\n",
            "|    ep_snr                 | 28.748886       |\n",
            "| time/                     |                 |\n",
            "|    fps                    | 5               |\n",
            "|    iterations             | 7               |\n",
            "|    time_elapsed           | 10370           |\n",
            "|    total_timesteps        | 57344           |\n",
            "| train/                    |                 |\n",
            "|    approx_kl              | 0.026922885     |\n",
            "|    clip_fraction          | 0.281           |\n",
            "|    clip_range             | 0.2             |\n",
            "|    entropy_loss           | -2.88           |\n",
            "|    explained_variance     | 0               |\n",
            "|    learning_rate          | 0.0003          |\n",
            "|    loss                   | -0.0545         |\n",
            "|    n_updates              | 60              |\n",
            "|    policy_gradient_loss   | -0.0537         |\n",
            "|    std                    | 0.665           |\n",
            "|    value_loss             | 0.0247          |\n",
            "-----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [5000, 10, 20] |\n",
            "|    ep_ber                 | 0.00318        |\n",
            "|    ep_extraction_accuracy | 0.992          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.796          |\n",
            "|    ep_reward              | 0.845          |\n",
            "|    ep_snr                 | 31.656376      |\n",
            "| time/                     |                |\n",
            "|    fps                    | 5              |\n",
            "|    iterations             | 8              |\n",
            "|    time_elapsed           | 11343          |\n",
            "|    total_timesteps        | 65536          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.021788023    |\n",
            "|    clip_fraction          | 0.208          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -2.71          |\n",
            "|    explained_variance     | 0              |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | -0.0344        |\n",
            "|    n_updates              | 70             |\n",
            "|    policy_gradient_loss   | -0.0373        |\n",
            "|    std                    | 0.638          |\n",
            "|    value_loss             | 0.0158         |\n",
            "----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [5000, 10, 20] |\n",
            "|    ep_ber                 | 0.00403        |\n",
            "|    ep_extraction_accuracy | 0.989          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.799          |\n",
            "|    ep_reward              | 0.849          |\n",
            "|    ep_snr                 | 32.465374      |\n",
            "| time/                     |                |\n",
            "|    fps                    | 5              |\n",
            "|    iterations             | 9              |\n",
            "|    time_elapsed           | 12307          |\n",
            "|    total_timesteps        | 73728          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.013746795    |\n",
            "|    clip_fraction          | 0.166          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -2.58          |\n",
            "|    explained_variance     | 0              |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | -0.0166        |\n",
            "|    n_updates              | 80             |\n",
            "|    policy_gradient_loss   | -0.0246        |\n",
            "|    std                    | 0.62           |\n",
            "|    value_loss             | 0.0105         |\n",
            "----------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                  |                |\n",
            "|    ep_action              | [5473, 10, 20] |\n",
            "|    ep_ber                 | 0.00187        |\n",
            "|    ep_extraction_accuracy | 0.985          |\n",
            "|    ep_len_mean            | 1              |\n",
            "|    ep_rew_mean            | 0.802          |\n",
            "|    ep_reward              | 0.81           |\n",
            "|    ep_snr                 | 27.54478       |\n",
            "| time/                     |                |\n",
            "|    fps                    | 6              |\n",
            "|    iterations             | 10             |\n",
            "|    time_elapsed           | 13293          |\n",
            "|    total_timesteps        | 81920          |\n",
            "| train/                    |                |\n",
            "|    approx_kl              | 0.013847067    |\n",
            "|    clip_fraction          | 0.138          |\n",
            "|    clip_range             | 0.2            |\n",
            "|    entropy_loss           | -2.48          |\n",
            "|    explained_variance     | 0              |\n",
            "|    learning_rate          | 0.0003         |\n",
            "|    loss                   | 0.00155        |\n",
            "|    n_updates              | 90             |\n",
            "|    policy_gradient_loss   | -0.0135        |\n",
            "|    std                    | 0.606          |\n",
            "|    value_loss             | 0.00645        |\n",
            "----------------------------------------------\n",
            "Trained model saved to _assets/ppo_audio_stego_model\n"
          ]
        }
      ],
      "source": [
        "# Initialize the framework\n",
        "cfg = Config()\n",
        "framework = RLAudioSteganography(cfg, method=\"spread-spectrum\")\n",
        "\n",
        "# --- Training Phase ---\n",
        "\n",
        "# Initialize components with the training audio\n",
        "# framework.Initialize_components(sample_path, method=\"spread-spectrum\")\n",
        "\n",
        "# Train PPO agent\n",
        "print(\"Training PPO agent...\")\n",
        "model = framework.train_ppo()\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = \"_assets/ppo_audio_stego_model\"\n",
        "model.save(model_save_path)\n",
        "print(f\"Trained model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# auto download model to local storage\n",
        "from google.colab import files\n",
        "files.download(f\"{model_save_path}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hCY6YpPuxv4j",
        "outputId": "d8c6df94-1dbc-4591-f390-85d3c7d47a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7ba9585-616a-4bcf-bee6-4e222de99704\", \"ppo_audio_stego_model.zip\", 4228399)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = f\"kratosgado/Audio_Steganography_PPO_model/pyTorch/no_steganalysis\"\n",
        "model_files = \"_assets\"\n",
        "kagglehub.model_upload(model_name, model_files, 'Apache 2.0')"
      ],
      "metadata": {
        "id": "rAHpszlZXgJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4770f103-cc16-4b7d-bc91-0419ad8cf7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading Model https://www.kaggle.com/models/kratosgado/Audio_Steganography_PPO_model/pyTorch/no_steganalysis ...\n",
            "More than 50 files detected, creating a zip archive...\n",
            "Starting upload for file /tmp/tmpwlk6f1ku/archive.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.8M/14.8M [00:00<00:00, 17.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload successful: /tmp/tmpwlk6f1ku/archive.zip (14MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your model instance version has been created.\n",
            "Files are being processed...\n",
            "See at: https://www.kaggle.com/models/kratosgado/Audio_Steganography_PPO_model/pyTorch/no_steganalysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH9P_-wMHSiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d419e8-d8b7-4b94-c872-c149c46d2b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from _assets/ppo_audio_stego_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/audioread/rawread.py:16: DeprecationWarning: 'aifc' is deprecated and slated for removal in Python 3.13\n",
            "  import aifc\n",
            "/usr/local/lib/python3.11/dist-packages/audioread/rawread.py:17: DeprecationWarning: 'audioop' is deprecated and slated for removal in Python 3.13\n",
            "  import audioop\n",
            "/usr/local/lib/python3.11/dist-packages/audioread/rawread.py:19: DeprecationWarning: 'sunau' is deprecated and slated for removal in Python 3.13\n",
            "  import sunau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stego audio saved to test.wav\n",
            "\n",
            "Original Message: \n",
            "    Embed a message into an audio file.\n",
            "\n",
            "    Parameters:\n",
            "      audio_path (str): Path to the audio file.\n",
            "      message (str): The message to be embedded.\n",
            "      output_path (str): Path to save the embedded audio file.\n",
            "    \n",
            "Extracted Message: Âº    Embed a message into an audio file.\n",
            "\n",
            "    Parameters:\n",
            "      audio_path (str): Path to the audio file.\n",
            "      messafe (str): The message to be embedded.\n",
            "      output_path (str): Path to save the embedded audio file.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "cfg = Config()\n",
        "framework_test = RLAudioSteganography(cfg, method=\"spread-spectrum\")\n",
        "\n",
        "message = \"\"\"\n",
        "    Embed a message into an audio file.\n",
        "\n",
        "    Parameters:\n",
        "      audio_path (str): Path to the audio file.\n",
        "      message (str): The message to be embedded.\n",
        "      output_path (str): Path to save the embedded audio file.\n",
        "    \"\"\"\n",
        "output_path = \"test.wav\"\n",
        "\n",
        "# framework_test.Initialize_components(audio_path=sample_path, method=\"spread-spectrum\")\n",
        "# Load the saved model\n",
        "model_test = PPO.load(model_save_path)\n",
        "print(f\"Loaded model from {model_save_path}\")\n",
        "# Embed message using the loaded model\n",
        "framework_test.embed_message(sample_path, message, output_path, model_test)\n",
        "\n",
        "# Extract message from the new stego audio\n",
        "extracted_message = framework_test.extract_message(output_path, len(message))\n",
        "print(f\"\\nOriginal Message: {message}\")\n",
        "print(f\"Extracted Message: {extracted_message}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujblC_zM3PDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb055ba8508d44d3838b2ddbe379b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_56250b93e8a84f4395db018c19817297"
          }
        },
        "d935e22d64ee44c7844cbe85de09676b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25672cca492417e87f503074fab7377",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_06049b0cbf6b470da7f9ff3257afd96d",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "a4c91c2049b040358dd65201db33a67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1f703bbf0330406a9217e281736c95e0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0ac0e72d8d642c887b38c262e80d6d5",
            "value": "kratosgado"
          }
        },
        "d2a2328006734257934ba1885cc382c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a668c9be13c547a1825af9ea3fb1a8ed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34d5ede13a584c858f0e525743884101",
            "value": ""
          }
        },
        "44bceaeed03e49dd89bdea25894872a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e06b0b41115847fd8514ee2e4b2121e0",
            "style": "IPY_MODEL_825e578844224fae84b9310e8471b938",
            "tooltip": ""
          }
        },
        "253a2ca42a0945a694e1085071e038b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc6cac27ce54f5b848940ebf3e66cc5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9f961788d2f747c5b015e00d0b808fc7",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "56250b93e8a84f4395db018c19817297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a25672cca492417e87f503074fab7377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06049b0cbf6b470da7f9ff3257afd96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f703bbf0330406a9217e281736c95e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ac0e72d8d642c887b38c262e80d6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a668c9be13c547a1825af9ea3fb1a8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d5ede13a584c858f0e525743884101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e06b0b41115847fd8514ee2e4b2121e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825e578844224fae84b9310e8471b938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ccc6cac27ce54f5b848940ebf3e66cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f961788d2f747c5b015e00d0b808fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aa32faea90741138938f70dbd9ff785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92320fc983f04a80ae025a0ee4fdb494",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ba5add594004752ad534d5e69e315f1",
            "value": "Connecting..."
          }
        },
        "92320fc983f04a80ae025a0ee4fdb494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba5add594004752ad534d5e69e315f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}